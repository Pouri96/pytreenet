{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytreenet as ptn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_state(ttn, bond_dim=2 , physical_dim= 2):\n",
    "    product_state = deepcopy(ttn)\n",
    "    A = np.array([1, 0]) \n",
    "    #A = np.random.rand(2) + 1j * np.random.rand(2)\n",
    "    for node_id in product_state.nodes.keys():\n",
    "        n = product_state.tensors[node_id].ndim - 1\n",
    "        tensor = A.reshape((1,) * n + (physical_dim,))\n",
    "        T = np.pad(tensor, n*((bond_dim-1, bond_dim-1),) + ((0, 0),))\n",
    "        product_state.tensors[node_id] = T\n",
    "        product_state.nodes[node_id].link_tensor(T)  \n",
    "    return product_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (0, 0): (2, 2, 2) --> (2, 2, 2, 2)\n",
    "\n",
    "shapes = {\n",
    "    (0, 0): (2, 2, 2, 2),\n",
    "    (0, 1): (2, 2, 2, 2),\n",
    "    (0, 2): (2, 2, 2, 2),\n",
    "    (0, 3): (2, 2),\n",
    "    (1, 0): (2, 2, 2),\n",
    "    (1, 1): (2, 2),\n",
    "    (1, 2): (2, 2, 2),\n",
    "    (1, 3): (2, 2),\n",
    "    (2, 0): (2, 2, 2, 2),\n",
    "    (2, 1): (2, 2, 2),\n",
    "    (2, 2): (2, 2, 2),\n",
    "    (2, 3): (2, 2),\n",
    "    (3, 0): (2, 2),\n",
    "    (3, 1): (2, 2, 2),\n",
    "    (3, 2): (2, 2, 2, 2),\n",
    "    (3, 3): (2, 2)\n",
    "}\n",
    "\n",
    "sites = {\n",
    "    (i, j): ptn.random_tensor_node(shapes[(i, j)], identifier=f\"Site({i},{j})\") for i in range(4) for j in range(4)\n",
    "}\n",
    "\n",
    "ttn = ptn.TreeTensorNetworkState()\n",
    "\n",
    "ttn.add_root(sites[(0, 0)][0], sites[(0, 0)][1])\n",
    "\n",
    "connections = [\n",
    "    ((0, 0), (0, 1), 0, 0),\n",
    "    ((0, 1), (1, 1), 1, 0),\n",
    "    ((0, 1), (0, 2), 2, 0),\n",
    "    ((0, 2), (1, 2), 1, 0),\n",
    "    ((1, 2), (1, 3), 1, 0),\n",
    "    ((0, 2), (0, 3), 2, 0),\n",
    "    ((0, 0), (1, 0), 1, 0),\n",
    "    ((1, 0), (2, 0), 1, 0),\n",
    "    ((2, 0), (3, 0), 1, 0),\n",
    "    ((2, 0), (2, 1), 2, 0),\n",
    "    ((2, 1), (3, 1), 1, 0),\n",
    "    ((3, 1), (3, 2), 1, 0),\n",
    "    ((3, 2), (2, 2), 1, 0),\n",
    "    ((2, 2), (2, 3), 1, 0),\n",
    "    ((3, 2), (3, 3), 2, 0),\n",
    "]\n",
    "\n",
    "for (parent, child, parent_leg, child_leg) in connections:\n",
    "    parent_id = f\"Site({parent[0]},{parent[1]})\"\n",
    "    child_id = f\"Site({child[0]},{child[1]})\"\n",
    "    ttn.add_child_to_parent(sites[child][0], sites[child][1], child_leg, parent_id, parent_leg)\n",
    "\n",
    "ttn = product_state(ttn , bond_dim= 4, physical_dim = 2)  \n",
    "\n",
    "nodes = {\n",
    "    (i, j): (ptn.Node(tensor=ttn.tensors[f\"Site({i},{j})\"].conj() , identifier=f\"Node({i},{j})\"), ttn.tensors[f\"Site({i},{j})\"].conj()) for i in range(4) for j in range(4)\n",
    "}\n",
    "\n",
    "ttn.add_child_to_parent(nodes[(0,0)][0], nodes[(0,0)][1], 2, \"Site(0,0)\", 2)\n",
    "\n",
    "### (0,0) : 0,1 --> 1,2\n",
    "\n",
    "connections = [\n",
    "    ((0, 0), (0, 1), 1, 0),\n",
    "    ((0, 1), (1, 1), 1, 0),\n",
    "    ((0, 1), (0, 2), 2, 0),\n",
    "    ((0, 2), (1, 2), 1, 0),\n",
    "    ((1, 2), (1, 3), 1, 0),\n",
    "    ((0, 2), (0, 3), 2, 0),\n",
    "    ((0, 0), (1, 0), 2, 0),\n",
    "    ((1, 0), (2, 0), 1, 0),\n",
    "    ((2, 0), (3, 0), 1, 0),\n",
    "    ((2, 0), (2, 1), 2, 0),\n",
    "    ((2, 1), (3, 1), 1, 0),\n",
    "    ((3, 1), (3, 2), 1, 0),\n",
    "    ((3, 2), (2, 2), 1, 0),\n",
    "    ((2, 2), (2, 3), 1, 0),\n",
    "    ((3, 2), (3, 3), 2, 0),\n",
    "]\n",
    "\n",
    "for (parent, child, parent_leg, child_leg) in connections:\n",
    "    parent_id = f\"Node({parent[0]},{parent[1]})\"\n",
    "    child_id = f\"Node({child[0]},{child[1]})\"\n",
    "    ttn.add_child_to_parent(nodes[child][0], nodes[child][1], child_leg, parent_id, parent_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = {\n",
    "    (0, 0): (3, 5, 6, d),\n",
    "    (0, 1): (3, 7, d),\n",
    "    (0, 2): (7, 8, d),\n",
    "    (1, 0): (5, 5, d),\n",
    "    (1, 1): (9, d),\n",
    "    (1, 2): (8, d),\n",
    "    (2, 0): (5, 6, d),\n",
    "    (2, 1): (6, 9, 3, d),\n",
    "    (2, 2): (3, d)\n",
    "}\n",
    "\n",
    "\n",
    "sites = {\n",
    "    (i, j): ptn.random_tensor_node(shapes[(i, j)], identifier=f\"Site({i},{j})\") for i in range(3) for j in range(3)\n",
    "}\n",
    "\n",
    "ttn = ptn.TreeTensorNetworkState()\n",
    "\n",
    "ttn.add_root(sites[(0, 0)][0], sites[(0, 0)][1])\n",
    "\n",
    "connections = [\n",
    "    ((0, 0), (0, 1), 0, 0),\n",
    "    ((0, 1), (0, 2), 1, 0),\n",
    "    ((0, 2), (1, 2), 1, 0),\n",
    "    ((0, 0), (1, 0), 1, 0),\n",
    "    ((1, 0), (2, 0), 1, 0),\n",
    "    ((2, 0), (2, 1), 1, 0),\n",
    "    ((2, 1), (1, 1), 1, 0),\n",
    "    ((2, 1), (2, 2), 2, 0)]\n",
    "\n",
    "\n",
    "for (parent, child, parent_leg, child_leg) in connections:\n",
    "    parent_id = f\"Site({parent[0]},{parent[1]})\"\n",
    "    child_id = f\"Site({child[0]},{child[1]})\"\n",
    "    ttn.add_child_to_parent(sites[child][0], sites[child][1], child_leg, parent_id, parent_leg)\n",
    "\n",
    "ttn = product_state(ttn , bond_dim= 4, physical_dim = d)\n",
    "\n",
    "nodes = {\n",
    "    (i, j): (ptn.Node(tensor=ttn.tensors[f\"Site({i},{j})\"] , identifier=f\"Node({i},{j})\"), ttn.tensors[f\"Site({i},{j})\"]) for i in range(3) for j in range(3)\n",
    "}\n",
    "\n",
    "ttn.add_child_to_parent(nodes[(0,0)][0], nodes[(0,0)][1], 2, \"Site(0,0)\", 2)\n",
    "\n",
    "connections = [\n",
    "    ((0, 0), (0, 1), 1, 0),\n",
    "    ((0, 1), (0, 2), 1, 0),\n",
    "    ((0, 2), (1, 2), 1, 0),\n",
    "    ((0, 0), (1, 0), 2, 0),\n",
    "    ((1, 0), (2, 0), 1, 0),\n",
    "    ((2, 0), (2, 1), 1, 0),\n",
    "    ((2, 1), (1, 1), 1, 0),\n",
    "    ((2, 1), (2, 2), 2, 0),\n",
    "]\n",
    "\n",
    "for (parent, child, parent_leg, child_leg) in connections:\n",
    "    parent_id = f\"Node({parent[0]},{parent[1]})\"\n",
    "    child_id = f\"Node({child[0]},{child[1]})\"\n",
    "    ttn.add_child_to_parent(nodes[child][0], nodes[child][1], child_leg, parent_id, parent_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors_periodic_in_legs(x, y, Lx, Ly):\n",
    "  neighbors = []\n",
    "  \n",
    "  # Right neighbor (with periodic boundary)\n",
    "  right_x = (x + 1) % Lx\n",
    "  neighbors.append((f\"Site({right_x},{y})\"))\n",
    "  \n",
    "  # Up neighbor (with periodic boundary)\n",
    "  up_y = (y + 1) % Ly\n",
    "  neighbors.append((f\"Site({x},{up_y})\"))\n",
    "  \n",
    "  return neighbors\n",
    "\n",
    "def get_neighbors_periodic_out_legs(x, y, Lx, Ly):\n",
    "    neighbors = []\n",
    "    \n",
    "    # Right neighbor (with periodic boundary)\n",
    "    right_x = (x + 1) % Lx\n",
    "    neighbors.append((f\"Node({right_x},{y})\"))\n",
    "    \n",
    "    # Up neighbor (with periodic boundary)\n",
    "    up_y = (y + 1) % Ly\n",
    "    neighbors.append((f\"Node({x},{up_y})\"))\n",
    "    \n",
    "    return neighbors  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anisotropic_Heisenberg_ham(J_x, J_y, J_z, h_z, Lx, Ly):\n",
    "    # Get the Pauli matrices\n",
    "    X, Y, Z = ptn.pauli_matrices()\n",
    "    \n",
    "    # Create a conversion dictionary for the operators\n",
    "    conversion_dict = {\n",
    "        \"X\": X,\n",
    "        \"J_x * X\": J_x * X,\n",
    "        \"Y\": Y,\n",
    "        \"J_y * Y\": J_y * Y,\n",
    "        \"Z\": Z,\n",
    "        \"J_z * Z\": J_z * Z,\n",
    "        \"I2\": np.eye(2),\n",
    "        \"h_z * Z\": h_z * Z\n",
    "    }\n",
    "    \n",
    "    terms = []\n",
    "    \n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            neighbors = get_neighbors_periodic_in_legs(x, y, Lx, Ly)\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                terms.append(ptn.TensorProduct({current_site: \"X\", neighbor: \"J_x * X\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"Y\", neighbor: \"J_y * Y\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"Z\", neighbor: \"J_z * Z\"}))               \n",
    "\n",
    "    \n",
    "    # On-site magnetic field terms\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({current_site: \"h_z * Z\"}))\n",
    "    \n",
    "    return ptn.Hamiltonian(terms, conversion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Liouville_Heisenberg(Lx, Ly, J_x, J_y, J_z, h_z, L, J):\n",
    "    # Get the Pauli matrices\n",
    "    X, Y, Z = ptn.pauli_matrices()\n",
    "    \n",
    "    # Create the conversion dictionary for the Hamiltonian.\n",
    "    conversion_dict = {\n",
    "        \"-iJ_x * X\": -1j*J_x * (X),\n",
    "        \"X\":                   (X),\n",
    "        \"-iJ_Y * Y\": -1j*J_y * (Y),\n",
    "        \"Y\":                   (Y),\n",
    "        \"-iJ_z * Z\": -1j*J_z * (Z),\n",
    "        \"Z\":                   (Z),\n",
    "        \"I2\":          np.eye(2),\n",
    "        \"-ih_z * Z\":  -1j* h_z * Z\n",
    "    }\n",
    "    \n",
    "    terms = []\n",
    "    \n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            neighbors = get_neighbors_periodic_in_legs(x, y, Lx, Ly)\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                terms.append(ptn.TensorProduct({current_site: \"-iJ_x * X\", neighbor: \"X\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"-iJ_Y * Y\", neighbor: \"Y\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"-iJ_z * Z\", neighbor: \"Z\"}))     \n",
    "\n",
    "    \n",
    "    # On-site magnetic field terms\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({current_site: \"-ih_z * Z\"}))\n",
    "\n",
    "    H1 = ptn.Hamiltonian(terms, conversion_dict)\n",
    "    \n",
    "    # H.T = H \n",
    "    \n",
    "    # Create the conversion dictionary for the Hamiltonian\n",
    "    conversion_dict = {\n",
    "        \"iJ_x * X.T\": 1j*J_x * (X.T),\n",
    "        \"X.T\":                 (X.T),\n",
    "        \"iJ_Y * Y.T\": 1j*J_y * (Y.T),\n",
    "        \"Y.T\":                 (Y.T),\n",
    "        \"iJ_z * Z.T\": 1j*J_z * (Z.T),\n",
    "        \"Z.T\":                 (Z.T),\n",
    "        \"I2\":              np.eye(2),\n",
    "        \"ih_z * Z.T\":     1j* h_z * (Z.T)\n",
    "    }\n",
    "    \n",
    "    terms = []\n",
    "    \n",
    "    # Hopping terms for the transpose\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Node({x},{y})\"\n",
    "            neighbors = get_neighbors_periodic_out_legs(x, y, Lx, Ly)\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                terms.append(ptn.TensorProduct({current_site: \"iJ_x * X.T\", neighbor: \"X.T\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"iJ_Y * Y.T\", neighbor: \"Y.T\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"iJ_z * Z.T\", neighbor: \"Z.T\"})) \n",
    "\n",
    "\n",
    "    # On-site magnetic field terms\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Node({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({current_site: \"ih_z * Z.T\"}))\n",
    "    \n",
    "    H2 = ptn.Hamiltonian(terms, conversion_dict)    \n",
    "    H1.__add__(H2)\n",
    "    \n",
    "    conversion_dict = {\n",
    "        \"L\": np.sqrt(J) * L,\n",
    "        \"L^dagger.T\": np.sqrt(J) * L.conj().T,\n",
    "        \"-1/2 (L^dagger @ L)\": -1/2 * J * (L.conj().T @ L),\n",
    "        \"-1/2 (L^dagger @ L).T\": -1/2 * J * (L.conj().T @ L).T\n",
    "    }\n",
    "\n",
    "    terms = []\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            out_site = f\"Node({x},{y})\"\n",
    "            in_site = f\"Site({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({in_site: \"L\"}))\n",
    "            terms.append(ptn.TensorProduct({out_site: \"L^dagger.T\"}))\n",
    "            terms.append(ptn.TensorProduct({in_site: \"-1/2 (L^dagger @ L)\"}))\n",
    "            terms.append(ptn.TensorProduct({out_site: \"-1/2 (L^dagger @ L).T\"}))\n",
    "\n",
    "    H3 = ptn.Hamiltonian(terms, conversion_dict)\n",
    "    H1.__add__(H3)\n",
    "    \n",
    "    return H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unitary(Lx, Ly, J_x, J_y, J_z, h_z):\n",
    "    # Get the Pauli matrices\n",
    "    X, Y, Z = ptn.pauli_matrices()\n",
    "    \n",
    "    # Create the conversion dictionary for the Hamiltonian\n",
    "    conversion_dict = {\n",
    "        \"-i * X\": -1j* X,\n",
    "        \"J_x * X\": J_x * X,\n",
    "        \"-i * Y\": -1j* Y,\n",
    "        \"J_y * Y\": J_y * Y,\n",
    "        \"-i * Z\": -1j* Z,\n",
    "        \"J_z * Z\": J_z * Z,\n",
    "        \"I2\": np.eye(2),\n",
    "        \"-i * h_z * Z\": -1j* h_z * Z\n",
    "    }\n",
    "    \n",
    "    terms = []\n",
    "    \n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            neighbors = get_neighbors_periodic_in_legs(x, y, Lx, Ly)\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                terms.append(ptn.TensorProduct({current_site: \"-i * X\", neighbor: \"J_x * X\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"-i * Y\", neighbor: \"J_y * Y\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"-i * Z\", neighbor: \"J_z * Z\"}))       \n",
    "\n",
    "    \n",
    "    # On-site magnetic field terms\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({current_site: \"-i * h_z * Z\"}))\n",
    "\n",
    "    H1 = ptn.Hamiltonian(terms, conversion_dict)\n",
    "    \n",
    "    # H.T = H \n",
    "    \n",
    "    # Create the conversion dictionary for the Hamiltonian\n",
    "    conversion_dict = {\n",
    "        \"i * X\": 1j* X,\n",
    "        \"J_x * X\": J_x * X,\n",
    "        \"i * Y\": 1j* Y,\n",
    "        \"J_y * Y\": J_y * Y,\n",
    "        \"i * Z\": 1j* Z,\n",
    "        \"J_z * Z\": J_z * Z,\n",
    "        \"I2\": np.eye(2),\n",
    "        \"i * h_z * Z\": 1j* h_z * Z\n",
    "    }\n",
    "    \n",
    "    terms = []\n",
    "    \n",
    "    # Hopping terms for the transpose\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Node({x},{y})\"\n",
    "            neighbors = get_neighbors_periodic_out_legs(x, y, Lx, Ly)\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                terms.append(ptn.TensorProduct({current_site: \"i * X\", neighbor: \"J_x * X\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"i * Y\", neighbor: \"J_y * Y\"}))\n",
    "                terms.append(ptn.TensorProduct({current_site: \"i * Z\", neighbor: \"J_z * Z\"})) \n",
    "\n",
    "\n",
    "    # On-site magnetic field terms\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Node({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({current_site: \"i * h_z * Z\"}))\n",
    "    \n",
    "    H2 = ptn.Hamiltonian(terms, conversion_dict)    \n",
    "    H1.__add__(H2)\n",
    "    \n",
    "    return H1    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Magnetization_op_total(Lx, Ly):\n",
    "    # Get the Pauli matrices\n",
    "    X, Y, Z = ptn.pauli_matrices()\n",
    "    \n",
    "    # Create a conversion dictionary for the operators\n",
    "    conversion_dict = {\n",
    "        \"X\": X ,\n",
    "        \"Y\": Y,\n",
    "        \"Z\": Z,\n",
    "        \"I2\": np.eye(2)}\n",
    "    terms = []\n",
    "    for x in range(Lx):\n",
    "        for y in range(Ly):\n",
    "            current_site = f\"Site({x},{y})\"\n",
    "            terms.append(ptn.TensorProduct({current_site: \"Z\"}))  # Using Z for magnetization\n",
    "\n",
    "    return ptn.Hamiltonian(terms, conversion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1+0j)\n",
      "(9+0j)\n"
     ]
    }
   ],
   "source": [
    "Lx =  3\n",
    "Ly  = 3\n",
    "J_x = 1\n",
    "J_y = 1.5 #(1.8)\n",
    "J_z = 0.4 \n",
    "h_z = 0\n",
    "\n",
    "\n",
    "# TTNO : Hamiltonian acting on in_legs\n",
    "H1 = Anisotropic_Heisenberg_ham(J_x, J_y, J_z, h_z, Lx, Ly)\n",
    "H1 = H1.pad_with_identities(ttn, symbolic= True)\n",
    "H = ptn.TTNO.from_hamiltonian(H1, ttn)\n",
    "\n",
    "# TTNO : Liouville operator \n",
    "X , Y , Z = ptn.pauli_matrices()\n",
    "L = (X - 1j * Y) / 2\n",
    "J = 0.2\n",
    "H1 = Liouville_Heisenberg(Lx, Ly, J_x, J_y, J_z, h_z, L, J)\n",
    "H1 = H1.pad_with_identities(ttn , symbolic= True)\n",
    "L_fancy = ptn.TTNO.from_hamiltonian(H1, ttn)\n",
    "\n",
    "# TTNO : Unitary operator\n",
    "H1 = Unitary(Lx, Ly, J_x, J_y, J_z, h_z)\n",
    "H1 = H1.pad_with_identities(ttn, symbolic= True)\n",
    "U = ptn.TTNO.from_hamiltonian(H1, ttn)\n",
    "\n",
    "M = Magnetization_op_total(Lx, Ly)\n",
    "M = M.pad_with_identities(ttn, symbolic= True)\n",
    "M = ptn.TTNO.from_hamiltonian(M, ttn)\n",
    "\n",
    "#ttn = ptn.normalize_ttn_Lindblad_4(ttn , 'Node(2,3)')\n",
    "I = ptn.TTNO.Identity(ttn)\n",
    "print(ttn.operator_expectation_value_Lindblad(I))\n",
    "print(ttn.operator_expectation_value_Lindblad(M) / ttn.operator_expectation_value_Lindblad(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttn = ptn.normalize_ttn_Lindblad_1_conj(ttn)\n",
    "tdvp_ex1 = ptn.SecondOrderOneSiteTDVP(initial_state = ttn,\n",
    "                                     hamiltonian = L_fancy,\n",
    "                                     time_step_size = 0.01,\n",
    "                                     final_time = 2,\n",
    "                                     operators = M,\n",
    "                                     num_vecs = 3,\n",
    "                                     tau = 1e-3,\n",
    "                                     SVDParameters = ptn.SVDParameters(max_bond_dim = np.inf , rel_tol= -np.inf , total_tol = -np.inf),\n",
    "                                     expansion_steps = 150000,\n",
    "                                     t3n_dict= {'Site(0,0)': 'Site(1,0)',\n",
    "                                                'Site(2,1)': 'Site(1,1)',\n",
    "                                                'Node(0,0)': 'Node(1,0)',\n",
    "                                                'Node(2,1)': 'Node(1,1)'},\n",
    "\n",
    "                                     Lanczos_threshold = np.inf,\n",
    "                                     k_fraction = 0.2, \n",
    "                                     validity_fraction = 1, \n",
    "                                     increase_fraction = 0.3,\n",
    "                                     max_iter = 1, \n",
    "\n",
    "                                     initial_tol= 1e-16,\n",
    "                                     tol_step= 10,\n",
    "                                     rel_tot_bond = 30,\n",
    "                                     max_bond= 220,\n",
    "                                     KrylovBasisMode = ptn.KrylovBasisMode.apply_1st_order_expansion,\n",
    "                                     config = ptn.TTNTimeEvolutionConfig(record_bond_dim=True,\n",
    "                                                                         Lindblad = True,\n",
    "                                                                         T3NS= False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9+0j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/201 [00:00<01:39,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.001517144228425+1.1273033261868673e-05j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/201 [00:00<01:09,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.00640482941033+9.872599661213844e-05j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/201 [00:00<00:58,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.01435366646835+0.00030812600633977163j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/201 [00:01<00:54,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.02474040469112+0.0006142405959262173j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/201 [00:01<00:51,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.03674183718517+0.0008975572358342064j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/201 [00:01<00:49,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.04938009867169+0.0009307089467698267j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/201 [00:01<00:48,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.06157754071807+0.0003793879065778128j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/201 [00:02<00:55,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.072217040672841-0.0011798082982750735j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/201 [00:02<00:58,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M : (9.080203093434582-0.00422467897578762j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtdvp_ex1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_ex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\time_evolution\\tdvp_algorithms\\secondorderonesite.py:347\u001b[0m, in \u001b[0;36mSecondOrderOneSiteTDVP.run_ex\u001b[1;34m(self, evaluation_time, filepath, pgbar)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;66;03m# Save current time\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, index] \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_step_size  \n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orthogonalize_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce_new\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tree_cache \u001b[38;5;241m=\u001b[39m PartialTreeCachDict()\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_partial_tree_cache() \n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\time_evolution\\tdvp_algorithms\\tdvp_algorithm.py:98\u001b[0m, in \u001b[0;36mTDVPAlgorithm._orthogonalize_init\u001b[1;34m(self, force_new)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;124;03mOrthogonalises the state to the start of the TDVP update path.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m        Defaults to False.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39morthogonality_center_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m force_new:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonical_form\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_path\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSplitMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKEEP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mmove_orthogonalization_center(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_path[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    102\u001b[0m                                              mode\u001b[38;5;241m=\u001b[39mSplitMode\u001b[38;5;241m.\u001b[39mKEEP)\n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\core\\ttn.py:1016\u001b[0m, in \u001b[0;36mTreeTensorNetwork.canonical_form\u001b[1;34m(self, orthogonality_center_id, mode, contr_mode)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcanonical_form\u001b[39m(\u001b[38;5;28mself\u001b[39m, orthogonality_center_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1004\u001b[0m                    mode: SplitMode \u001b[38;5;241m=\u001b[39m SplitMode\u001b[38;5;241m.\u001b[39mREDUCED,\n\u001b[0;32m   1005\u001b[0m                    contr_mode: ContractionMode \u001b[38;5;241m=\u001b[39m ContractionMode\u001b[38;5;241m.\u001b[39mVCONTR ):\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    Brings the TTN in canonical form with respect to a given orthogonality\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[38;5;124;03m     center.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;124;03m            refer to `tensor_util.tensor_qr_decomposition`.\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1016\u001b[0m     \u001b[43mcanonical_form\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morthogonality_center_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontr_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\core\\canonical_form.py:53\u001b[0m, in \u001b[0;36mcanonical_form\u001b[1;34m(ttn, orthogonality_center_id, mode, contr_mode)\u001b[0m\n\u001b[0;32m     49\u001b[0m minimum_distance_neighbour_id \u001b[38;5;241m=\u001b[39m _find_smallest_distance_neighbour(node,\n\u001b[0;32m     50\u001b[0m                                                                   distance_dict)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode,SplitMode):  \n\u001b[1;32m---> 53\u001b[0m     \u001b[43msplit_qr_contract_r_to_neighbour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mttn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mminimum_distance_neighbour_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode,SVDParameters):\n\u001b[0;32m     58\u001b[0m     split_svd_contract_sv_to_neighbour(ttn \u001b[38;5;241m=\u001b[39m ttn,\n\u001b[0;32m     59\u001b[0m                                       node_id \u001b[38;5;241m=\u001b[39m node_id,\n\u001b[0;32m     60\u001b[0m                                       neighbour_id \u001b[38;5;241m=\u001b[39m minimum_distance_neighbour_id,\n\u001b[0;32m     61\u001b[0m                                       SVDParameters \u001b[38;5;241m=\u001b[39m mode,\n\u001b[0;32m     62\u001b[0m                                       contr_mode \u001b[38;5;241m=\u001b[39m contr_mode)\n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\core\\canonical_form.py:210\u001b[0m, in \u001b[0;36msplit_qr_contract_r_to_neighbour\u001b[1;34m(ttn, node_id, neighbour_id, mode)\u001b[0m\n\u001b[0;32m    205\u001b[0m r_tensor_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid1()) \u001b[38;5;66;03m# Avoid identifier duplication\u001b[39;00m\n\u001b[0;32m    206\u001b[0m ttn\u001b[38;5;241m.\u001b[39msplit_node_qr(node_id, q_legs, r_legs,\n\u001b[0;32m    207\u001b[0m                     q_identifier\u001b[38;5;241m=\u001b[39mnode_id,\n\u001b[0;32m    208\u001b[0m                     r_identifier\u001b[38;5;241m=\u001b[39mr_tensor_id,\n\u001b[0;32m    209\u001b[0m                     mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m--> 210\u001b[0m \u001b[43mttn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontract_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighbour_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_tensor_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnew_identifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbour_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\core\\ttn.py:559\u001b[0m, in \u001b[0;36mTreeTensorNetwork.contract_nodes\u001b[1;34m(self, node_id1, node_id2, new_identifier)\u001b[0m\n\u001b[0;32m    557\u001b[0m     new_identifier \u001b[38;5;241m=\u001b[39m node_id1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m node_id2\n\u001b[0;32m    558\u001b[0m parent_id, child_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetermine_parentage(node_id1, node_id2)\n\u001b[1;32m--> 559\u001b[0m new_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_contraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_identifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m new_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_contracted_node(new_tensor, new_identifier,\n\u001b[0;32m    561\u001b[0m                                         parent_id, child_id, node_id1)\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# Change connectivity. This deletes the old nodes.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edpou\\Desktop\\PyTreeNet-Project_06\\pytreenet\\core\\ttn.py:589\u001b[0m, in \u001b[0;36mTreeTensorNetwork._data_contraction\u001b[1;34m(self, parent_id, child_id, new_id)\u001b[0m\n\u001b[0;32m    587\u001b[0m child_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors[child_id]\n\u001b[0;32m    588\u001b[0m axes \u001b[38;5;241m=\u001b[39m (parent_node\u001b[38;5;241m.\u001b[39mneighbour_index(child_id), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 589\u001b[0m new_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# This order for leg convention\u001b[39;49;00m\n\u001b[0;32m    590\u001b[0m \u001b[43m                          \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;66;03m## Remove old tensors\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mpop(parent_id)\n",
      "File \u001b[1;32mc:\\Users\\edpou\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\numeric.py:1121\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1119\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[0;32m   1120\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[1;32m-> 1121\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tdvp_ex1.run_ex(evaluation_time=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qutip import *\n",
    "import numpy as np\n",
    "\n",
    "# Define coupling constants for anisotropy\n",
    "Jx = 1  # Coupling in x-direction\n",
    "Jy = 1.5 # Coupling in y-direction\n",
    "Jz = 0.4  # Coupling in z-direction\n",
    "\n",
    "gamma_relax = 0.2 # Relaxation rate\n",
    "# gamma_dephase = 1  # Dephasing rate\n",
    "\n",
    "# Lattice dimensions\n",
    "Nx = 3  # Number of sites along x-direction\n",
    "Ny = 3  # Number of sites along y-direction\n",
    "N = Nx * Ny  # Total number of sites\n",
    "\n",
    "# Precompute the spin operators for each site\n",
    "sx_list = []\n",
    "sy_list = []\n",
    "sz_list = []\n",
    "sigmam_list = []\n",
    "\n",
    "si = qeye(2)  # Identity operator for a single qubit\n",
    "for n in range(N):\n",
    "  # List of identity operators for all sites\n",
    "  op_list = [si] * N\n",
    "  # Sx operator at site n\n",
    "  op_list[n] = sigmax()\n",
    "  sx = tensor(op_list)\n",
    "  sx_list.append(sx)\n",
    "  \n",
    "  # Sy operator at site n\n",
    "  op_list[n] = sigmay()\n",
    "  sy = tensor(op_list)\n",
    "  sy_list.append(sy)\n",
    "  \n",
    "  # Sz operator at site n\n",
    "  op_list[n] = sigmaz()\n",
    "  sz = tensor(op_list)\n",
    "  sz_list.append(sz)\n",
    "  \n",
    "  # S- (lowering) operator at site n\n",
    "  op_list[n] = sigmam()\n",
    "  sigmam_op = tensor(op_list)\n",
    "  sigmam_list.append(sigmam_op)\n",
    "\n",
    "# Function to map 2D lattice coordinates (i, j) to a site index\n",
    "def site(i, j):\n",
    "  \"\"\"Return the site index for coordinates (i, j), with periodic boundaries.\"\"\"\n",
    "  return (i % Nx) + (j % Ny) * Nx\n",
    "\n",
    "# Initialize the Hamiltonian\n",
    "H = 0\n",
    "\n",
    "# Build the Hamiltonian by summing over nearest neighbors with periodic boundary conditions\n",
    "for i in range(Nx):\n",
    "  for j in range(Ny):\n",
    "      n = site(i, j)  # Current site index\n",
    "      # Right neighbor (periodic boundary)\n",
    "      n_right = site(i + 1, j)\n",
    "      # Interaction terms with the right neighbor\n",
    "      H += Jx * sx_list[n] * sx_list[n_right]\n",
    "      H += Jy * sy_list[n] * sy_list[n_right]\n",
    "      H += Jz * sz_list[n] * sz_list[n_right]\n",
    "      \n",
    "      # Up neighbor (periodic boundary)\n",
    "      n_up = site(i, j + 1)\n",
    "      # Interaction terms with the up neighbor\n",
    "      H += Jx * sx_list[n] * sx_list[n_up]\n",
    "      H += Jy * sy_list[n] * sy_list[n_up]\n",
    "      H += Jz * sz_list[n] * sz_list[n_up]\n",
    "      \n",
    "\n",
    "# Option 1: All spins up |000...0> (Eigenstate of Sz_total)\n",
    "psi0 = tensor([basis(2, 0) for _ in range(N)]).unit()\n",
    "\n",
    "# Option 2: All spins in superposition |+⟩ = (|0⟩ + |1⟩)/sqrt(2)\n",
    "# psi0 = tensor([(basis(2, 0) + basis(2, 1)).unit() for _ in range(N)])\n",
    "\n",
    "# Option 3: Half spins excited |111...1000...0>\n",
    "# psi0 = tensor([basis(2, 1) if n < N//2 else basis(2, 0) for n in range(N)]).unit()\n",
    "\n",
    "\n",
    "# Define collapse operators (for the Lindblad equation)\n",
    "# For example, include relaxation and dephasing at each site\n",
    "\n",
    "\n",
    "c_ops = []\n",
    "\n",
    "for n in range(N):\n",
    "  # a. Relaxation (spin flip down) using lowering operator S-\n",
    "  c_ops.append(np.sqrt(gamma_relax) * sigmam_list[n])\n",
    "  \n",
    "  # b. Optional: Dephasing using Sz operator\n",
    "  # Uncomment the following lines if you wish to include dephasing\n",
    "  # c_ops.append(np.sqrt(gamma_dephase) * sz_list[n])\n",
    "\n",
    "# Time points where we want the solution\n",
    "total_time = 0.1  # Total time in seconds\n",
    "time_step = 0.001  # Time step in seconds\n",
    "\n",
    "# Create the time list\n",
    "tlist = np.arange(0, total_time + time_step, time_step)  # Include the endpoint\n",
    "\n",
    "\n",
    "# Observables to calculate - for instance, total magnetization in z-direction\n",
    "sz_total = sum(sz_list)\n",
    "\n",
    "# Solve the master equation\n",
    "result = mesolve(\n",
    "  H,        # Hamiltonian\n",
    "  psi0,     # Initial state\n",
    "  tlist,    # Time list\n",
    "  c_ops,    # Collapse operators\n",
    "  [sz_total]  # List of observables\n",
    "  # , [sz_first, sz_last]  # Uncomment to track individual spins\n",
    ")\n",
    "\n",
    "# Extract expectation values\n",
    "magnetization_z = result.expect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.        , 8.99638237, 8.99272948, 8.98904139, 8.98531812,\n",
       "       8.98155972, 8.97776622, 8.9739377 , 8.97007419, 8.96617575,\n",
       "       8.96224243, 8.95827431, 8.95427148, 8.950234  , 8.94616193,\n",
       "       8.94205534, 8.9379143 , 8.93373888, 8.92952923, 8.92528544,\n",
       "       8.92100761, 8.91669581, 8.91235014, 8.90797069, 8.90355755,\n",
       "       8.89911088, 8.89463079, 8.8901174 , 8.88557084, 8.88099124,\n",
       "       8.87637873, 8.87173345, 8.86705552, 8.86234509, 8.85760232,\n",
       "       8.85282734, 8.84802031, 8.84318138, 8.83831071, 8.83340845,\n",
       "       8.82847477, 8.82350982, 8.81851379, 8.81348684, 8.80842915,\n",
       "       8.80334091, 8.79822228, 8.79307347, 8.78789465, 8.78268602,\n",
       "       8.77744778, 8.7721801 , 8.7668832 , 8.76155726, 8.7562025 ,\n",
       "       8.75081912, 8.74540733, 8.73996735, 8.73449939, 8.72900367,\n",
       "       8.72348043, 8.71792987, 8.71235223, 8.70674774, 8.70111662,\n",
       "       8.69545908, 8.68977538, 8.68406574, 8.67833041, 8.67256962,\n",
       "       8.66678363, 8.66097269, 8.65513703, 8.64927693, 8.64339262,\n",
       "       8.63748438, 8.63155244, 8.62559707, 8.61961851, 8.61361703,\n",
       "       8.6075929 , 8.60154637, 8.59547773, 8.58938724, 8.58327518,\n",
       "       8.57714181, 8.57098742, 8.5648123 , 8.55861671, 8.55240093,\n",
       "       8.54616524, 8.5399099 , 8.53363522, 8.52734146, 8.52102892,\n",
       "       8.51469789, 8.50834866, 8.50198152, 8.49559676, 8.48919469,\n",
       "       8.48277559])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magnetization_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1, axs1 = plt.subplots(1, 1, sharex=True, figsize=(5, 5))\n",
    "\n",
    "axs1.plot( tdvp_ex1.operator_results()[0] , label=\"gamma = 0\")\n",
    "axs1.plot( magnetization_z , label=\"gamma = ex\")\n",
    "\n",
    "axs1.set_xlabel(\"Time $t$\")\n",
    "axs1.set_ylabel(\"Total Occupation \")\n",
    "axs1.grid(True)\n",
    "axs1.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = tdvp_ex1.times()\n",
    "tdvp_ex1.operator_results()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_distinct_colors(n):\n",
    "    \"\"\"Generates a list of n distinct, visually appealing colors using colormap cyclically.\"\"\"\n",
    "    from matplotlib.cm import get_cmap\n",
    "    cmap = get_cmap('tab20')  # Choose a colormap with more distinct colors\n",
    "    return [cmap(i / n) for i in range(n)]\n",
    "\n",
    "# Create a figure with a grid of subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# Set a title for the entire figure\n",
    "plt.suptitle(\n",
    "    r'$\\hat{H}=\\sum_{\\langle i j\\rangle}\\left(J_x \\hat{X}_i \\hat{X}_j+J_y \\hat{Y}_i \\hat{Y}_j+J_z \\hat{Z}_i \\hat{Z}_j\\right)+\\sum_i h_z \\hat{Z}_i$' + '\\n' + \n",
    "    r'$(J_x,J_y,J_z,h_z,\\gamma) = (0.9, 1, 1, 0, 1) $' + '\\n' +\n",
    "    r'$time\\_step = 0.001$' + '\\n' +\n",
    "    r'$run\\ time = 45 min $',\n",
    "    fontsize=30, y=0.98\n",
    ")\n",
    "\n",
    "# Plot max bond dimension\n",
    "axs[0, 0].plot(tdvp_ex1.max_bond_dim, linewidth=3)\n",
    "axs[0, 0].set_xlabel(\"Time $t$\", fontsize=15)\n",
    "axs[0, 0].set_ylabel('Max Bond Dimension', fontsize=15)\n",
    "axs[0, 0].tick_params(axis='both', which='major', labelsize=20)\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "# Plot total bond dimension\n",
    "axs[0, 1].plot(tdvp_ex1.total_bond_dim, linewidth=3)\n",
    "axs[0, 1].set_xlabel(\"Time $t$\", fontsize=15)\n",
    "axs[0, 1].set_ylabel('Total Bond Dimension', fontsize=15)\n",
    "axs[0, 1].tick_params(axis='both', which='major', labelsize=20)\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "# Plot bond dimensions for each key\n",
    "colors = get_distinct_colors(len(tdvp_ex1.bond_dims))\n",
    "for i, (key, values) in enumerate(tdvp_ex1.bond_dims.items()):\n",
    "    x = list(range(len(values)))\n",
    "    axs[1, 0].plot(x, values, label=key, color=colors[i], linewidth=3)\n",
    "axs[1, 0].legend(title='Bond Dimensions', loc='upper left', bbox_to_anchor=(1, 1), fontsize=14, title_fontsize=16)\n",
    "axs[1, 0].set_xlabel(\"Time $t$\", fontsize=18)\n",
    "axs[1, 0].set_ylabel('Bond dimensions', fontsize=15)\n",
    "axs[1, 0].set_title('Time (timestep = 0.01)', fontsize=15)\n",
    "axs[1, 0].tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.subplots_adjust(right=0.8)\n",
    "\n",
    "# Plot results_M\n",
    "axs[1, 1].plot(times , tdvp_ex1.operator_results()[0], label=\"Total Magnetization\", linewidth=3)\n",
    "axs[1, 1].set_xlabel(\"Time $t$\", fontsize=15)\n",
    "axs[1, 1].set_ylabel(\"Total Magnetization\", fontsize=15)\n",
    "axs[1, 1].grid(True)\n",
    "axs[1, 1].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make room for the title\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (0, 0): (2, 2, 2) --> (2, 2, 2, 2)\n",
    "\n",
    "shapes = {\n",
    "    (0, 0): (2, 2, 2),\n",
    "    (0, 1): (2, 2, 2),\n",
    "    (0, 2): (2, 2, 2, 2),\n",
    "    (0, 3): (2, 2),\n",
    "    (1, 0): (2, 2),\n",
    "    (1, 1): (2, 2, 2, 2),\n",
    "    (1, 2): (2, 2, 2, 2),\n",
    "    (1, 3): (2, 2),\n",
    "    (2, 0): (2, 2),\n",
    "    (2, 1): (2, 2, 2, 2),\n",
    "    (2, 2): (2, 2, 2, 2),\n",
    "    (2, 3): (2, 2),\n",
    "    (3, 0): (2, 2),\n",
    "    (3, 1): (2, 2, 2),\n",
    "    (3, 2): (2, 2, 2, 2),\n",
    "    (3, 3): (2, 2)\n",
    "}\n",
    "\n",
    "sites = {\n",
    "    (i, j): ptn.random_tensor_node(shapes[(i, j)], identifier=f\"Site({i},{j})\") for i in range(4) for j in range(4)\n",
    "}\n",
    "\n",
    "ttn = ptn.TreeTensorNetworkState()\n",
    "\n",
    "ttn.add_root(sites[(0, 0)][0], sites[(0, 0)][1])\n",
    "\n",
    "connections = [\n",
    "    ((0, 0), (0, 1), 0, 0),\n",
    "    ((0, 1), (0, 2), 1, 0),\n",
    "    ((0, 2), (0, 3), 1, 0),\n",
    "    ((0, 2), (1, 2), 2, 0),\n",
    "    ((1, 2), (1, 3), 1, 0),\n",
    "    ((1, 2), (1, 1), 2, 0),\n",
    "    ((1, 1), (1, 0), 1, 0),\n",
    "    ((1, 1), (2, 1), 2, 0),\n",
    "    ((2, 1), (2, 0), 1, 0),\n",
    "    ((2, 1), (2, 2), 2, 0),\n",
    "    ((2, 2), (2, 3), 1, 0),\n",
    "    ((2, 2), (3, 2), 2, 0),\n",
    "    ((3, 2), (3, 3), 1, 0),\n",
    "    ((3, 2), (3, 1), 2, 0),\n",
    "    ((3, 1), (3, 0), 1, 0),\n",
    "    ]\n",
    "\n",
    "for (parent, child, parent_leg, child_leg) in connections:\n",
    "    parent_id = f\"Site({parent[0]},{parent[1]})\"\n",
    "    child_id = f\"Site({child[0]},{child[1]})\"\n",
    "    ttn.add_child_to_parent(sites[child][0], sites[child][1], child_leg, parent_id, parent_leg)\n",
    "\n",
    "ttn = product_state(ttn , bond_dim= 2, physical_dim = 2)  \n",
    "\n",
    "nodes = {\n",
    "    (i, j): (ptn.Node(tensor=ttn.tensors[f\"Site({i},{j})\"].conj() , identifier=f\"Node({i},{j})\"), ttn.tensors[f\"Site({i},{j})\"].conj()) for i in range(4) for j in range(4)\n",
    "}\n",
    "\n",
    "ttn.add_child_to_parent(nodes[(0,0)][0], nodes[(0,0)][1], 1, \"Site(0,0)\", 1)\n",
    "\n",
    "### (0,0) : 0,1 --> 1,2\n",
    "\n",
    "connections = [\n",
    "    ((0, 0), (0, 1), 1, 0),\n",
    "    ((0, 1), (0, 2), 1, 0),\n",
    "    ((0, 2), (0, 3), 1, 0),\n",
    "    ((0, 2), (1, 2), 2, 0),\n",
    "    ((1, 2), (1, 3), 1, 0),\n",
    "    ((1, 2), (1, 1), 2, 0),\n",
    "    ((1, 1), (1, 0), 1, 0),\n",
    "    ((1, 1), (2, 1), 2, 0),\n",
    "    ((2, 1), (2, 0), 1, 0),\n",
    "    ((2, 1), (2, 2), 2, 0),\n",
    "    ((2, 2), (2, 3), 1, 0),\n",
    "    ((2, 2), (3, 2), 2, 0),\n",
    "    ((3, 2), (3, 3), 1, 0),\n",
    "    ((3, 2), (3, 1), 2, 0),\n",
    "    ((3, 1), (3, 0), 1, 0),\n",
    "    ]\n",
    "\n",
    "for (parent, child, parent_leg, child_leg) in connections:\n",
    "    parent_id = f\"Node({parent[0]},{parent[1]})\"\n",
    "    child_id = f\"Node({child[0]},{child[1]})\"\n",
    "    ttn.add_child_to_parent(nodes[child][0], nodes[child][1], child_leg, parent_id, parent_leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config : Lindblad = True\n",
    "# time_evolve with exponent = hamiltonian * time_difference\n",
    "# evaluate_operator with operator_expectation_value_Lindblad(operator)\n",
    "# normalize_ttn_Lindblad after each run_one_time_step_ex\n",
    "\n",
    "tdvp_ex1 = ptn.SecondOrderOneSiteTDVP(initial_state = ttn,\n",
    "                                     hamiltonian = L_fancy,\n",
    "                                     time_step_size = 0.01,\n",
    "                                     final_time = 4,\n",
    "                                     operators = M,\n",
    "                                     num_vecs = 3,\n",
    "                                     tau = 1e-3,\n",
    "                                     SVDParameters = ptn.SVDParameters(max_bond_dim = np.inf , rel_tol= -np.inf , total_tol = -np.inf),\n",
    "                                     expansion_steps = 15,\n",
    "                                     t3n_dict = {'Site(0,2)': 'Site(0,1)',\n",
    "                                                'Site(1,2)': 'Site(1,1)',\n",
    "                                                'Site(1,1)': 'Site(2,1)',\n",
    "                                                'Site(2,1)': 'Site(2,2)',\n",
    "                                                'Site(2,2)': 'Site(2,1)',\n",
    "                                                'Site(3,2)': 'Site(3,3)',\n",
    "\n",
    "                                                'Node(0,2)': 'Node(0,1)',\n",
    "                                                'Node(1,2)': 'Node(1,1)',\n",
    "                                                'Node(1,1)': 'Node(2,1)',\n",
    "                                                'Node(2,1)': 'Node(2,2)',\n",
    "                                                'Node(2,2)': 'Node(2,1)',\n",
    "                                                'Node(3,2)': 'Node(3,3)'},\n",
    "\n",
    "                                     Lanczos_threshold = np.inf,\n",
    "                                     k_fraction = 0.2, \n",
    "                                     validity_fraction = 1, \n",
    "                                     increase_fraction = 0.3,\n",
    "                                     max_iter = 1, \n",
    "\n",
    "                                     initial_tol= 1e-16,\n",
    "                                     tol_step= 10,\n",
    "                                     rel_tot_bond = 30,\n",
    "                                     max_bond= 220,\n",
    "                                     norm_tol = 0,\n",
    "                                     KrylovBasisMode = ptn.KrylovBasisMode.apply_1st_order_expansion,\n",
    "                                     config = ptn.TTNTimeEvolutionConfig(record_bond_dim=True,\n",
    "                                                                         Lindblad = True,\n",
    "                                                                         T3NS= False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Union\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from dataclasses import replace\n",
    "from ...operators.tensorproduct import TensorProduct\n",
    "from ...ttno.ttno_class import TTNO\n",
    "from ...ttns import (TreeTensorNetworkState , \n",
    "                     normalize_ttn_Lindblad_1 , \n",
    "                        normalize_ttn_Lindblad_1_conj ,\n",
    "                     normalize_ttn_Lindblad_3 , \n",
    "                        normalize_ttn_Lindblad_3_conj ,\n",
    "                     normalize_ttn_Lindblad_4 , \n",
    "                     normalize_ttn_Lindblad_5,\n",
    "                        normalize_ttn_Lindblad_5_conj,\n",
    "                     normalize_ttn_Lindblad_XX ,  )\n",
    "from ..ttn_time_evolution import TTNTimeEvolutionConfig\n",
    "from ..Subspace_expansion import expand_subspace , KrylovBasisMode , max_two_neighbour_form , original_form\n",
    "from ...util.tensor_splitting import SplitMode , SVDParameters\n",
    "from ...core.canonical_form import adjust_ttn1_structure_to_ttn2 , adjust_ttno_structure_to_ttn\n",
    "from pytreenet.contractions.state_operator_contraction import adjust_operator_to_ket , adjust_bra_to_ket\n",
    "from pytreenet.contractions.state_state_contraction import contract_ttn_Lindblad\n",
    "from .onesitetdvp import OneSiteTDVP\n",
    "from ...contractions.tree_cach_dict import PartialTreeCachDict\n",
    "from ...time_evolution.time_evo_util.update_path import TDVPUpdatePathFinder\n",
    "class SecondOrderOneSiteTDVP(OneSiteTDVP):\n",
    "    \"\"\"\n",
    "    The first order one site TDVP algorithm.\n",
    "\n",
    "    This means we have second order Trotter splitting for the time evolution:\n",
    "      exp(At+Bt) approx exp(At/2)*exp(Bt/2)*exp(Bt/2)*exp(At/2)\n",
    "\n",
    "    Has the same attributes as the TDVP-Algorithm clas with two additions.\n",
    "\n",
    "    Attributes:\n",
    "        backwards_update_path (List[str]): The update path that traverses\n",
    "            backwards.\n",
    "        backwards_orth_path (List[List[str]]): The orthogonalisation paths for\n",
    "            the backwards run.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 initial_state: TreeTensorNetworkState,\n",
    "                 hamiltonian: TTNO, \n",
    "                 time_step_size: float, \n",
    "                 final_time: float,\n",
    "                 operators: Union[TensorProduct, List[TensorProduct]],\n",
    "\n",
    "                 num_vecs: int , \n",
    "                 tau: float, \n",
    "                 SVDParameters : SVDParameters,\n",
    "                 expansion_steps: int = 10,\n",
    "                 t3n_dict: dict = None,\n",
    "\n",
    "                 Lanczos_threshold : float = 10,\n",
    "                 k_fraction : float = 0.6, \n",
    "                 validity_fraction : float = 0.8, \n",
    "                 increase_fraction : float = 0.3, \n",
    "                 max_iter : int = 10,  \n",
    "\n",
    "                 initial_tol: float = 1e-20,\n",
    "                 tol_step: float = 10, \n",
    "                 rel_tot_bond : int = 30,\n",
    "                 max_bond: int = 100,\n",
    "                 norm_tol: int = 0,\n",
    "                 KrylovBasisMode : KrylovBasisMode = KrylovBasisMode.apply_ham,                  \n",
    "                 config: Union[TTNTimeEvolutionConfig,None] = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the second order one site TDVP algorithm.\n",
    "\n",
    "        Args:\n",
    "            initial_state (TreeTensorNetworkState): The initial state of the\n",
    "                system.\n",
    "            hamiltonian (TTNO): The Hamiltonian of the system.\n",
    "            time_step_size (float): The time step size.\n",
    "            final_time (float): The final time of the evolution.\n",
    "            operators (Union[TensorProduct, List[TensorProduct]]): The operators\n",
    "                for which the expectation values are calculated.\n",
    "            config (Union[TTNTimeEvolutionConfig,None], optional): The time\n",
    "                evolution configuration. Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__(initial_state, hamiltonian,\n",
    "                         time_step_size, final_time, operators, num_vecs, \n",
    "                         tau,\n",
    "                         SVDParameters,\n",
    "                         expansion_steps,\n",
    "                         initial_tol,\n",
    "                         tol_step,\n",
    "                         rel_tot_bond,\n",
    "                         max_bond,\n",
    "                         KrylovBasisMode,  \n",
    "                         config)\n",
    "        self.t3n_dict = t3n_dict\n",
    "        self.Lanczos_threshold = Lanczos_threshold\n",
    "        self.k_fraction = k_fraction\n",
    "        self.validity_fraction = validity_fraction\n",
    "        self.increase_fraction = increase_fraction\n",
    "        self.max_iter = max_iter\n",
    "        self.norm_tol = norm_tol\n",
    "\n",
    "        if self.T3NS :\n",
    "           self._init_two_neighbour_form() \n",
    "        else:\n",
    "            self.hamiltonian = adjust_ttno_structure_to_ttn(self.hamiltonian , self.state)\n",
    "            self.update_path = TDVPUpdatePathFinder(self.state).find_path()\n",
    "            self.orthogonalization_path = self._find_tdvp_orthogonalization_path(self.update_path) \n",
    "            self.backwards_update_path = self._init_second_order_update_path()\n",
    "            self.backwards_orth_path = self._init_second_order_orth_path() \n",
    "            self._orthogonalize_init()\n",
    "            self.partial_tree_cache = PartialTreeCachDict()\n",
    "            self._init_partial_tree_cache()           \n",
    "\n",
    "    def _init_two_neighbour_form(self):\n",
    "        \"\"\"\n",
    "        Transform the state, Hamiltonian and operators into the max two neighbour form.\n",
    "        \"\"\"\n",
    "        self.hamiltonian = adjust_ttno_structure_to_ttn(self.hamiltonian , self.state)\n",
    "        self.state , dict1 = max_two_neighbour_form(self.state)\n",
    "        self.hamiltonian , _ = max_two_neighbour_form(self.hamiltonian , dict1)\n",
    "        list = []\n",
    "        for operators in self.operators: \n",
    "            operator , _ = max_two_neighbour_form(operators,dict1)\n",
    "            list.append(operator)\n",
    "        self.operators = list\n",
    "\n",
    "        self.hamiltonian = adjust_ttno_structure_to_ttn(self.hamiltonian , self.state)\n",
    "        self.update_path = TDVPUpdatePathFinder(self.state).find_path()\n",
    "        self.orthogonalization_path = self._find_tdvp_orthogonalization_path(self.update_path) \n",
    "        self.backwards_update_path = self._init_second_order_update_path()\n",
    "        self.backwards_orth_path = self._init_second_order_orth_path() \n",
    "        self.two_neighbour_form_dict = dict1\n",
    "        self._orthogonalize_init()\n",
    "        self.partial_tree_cache = PartialTreeCachDict()\n",
    "        self._init_partial_tree_cache()\n",
    "        \n",
    "    \n",
    "    def _init_second_order_update_path(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Find the update path that traverses backwards.\n",
    "        \"\"\"\n",
    "        return list(reversed(self.update_path))\n",
    "\n",
    "    def _init_second_order_orth_path(self) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Find the orthogonalisation paths for the backwards run.\n",
    "        \"\"\"\n",
    "        back_orthogonalization_path = []\n",
    "        for i, node_id in enumerate(self.backwards_update_path[1:-1]):\n",
    "            current_path = self.state.path_from_to(node_id,\n",
    "                                                   self.backwards_update_path[i+2])\n",
    "            current_path = current_path[:-1]\n",
    "            back_orthogonalization_path.append(current_path)\n",
    "        back_orthogonalization_path.append([self.backwards_update_path[-1]])\n",
    "        return back_orthogonalization_path\n",
    "\n",
    "    def _update_forward_site_and_link(self, node_id: str,\n",
    "                                      next_node_id: str):\n",
    "        \"\"\"\n",
    "        Run the forward update with half time step.\n",
    "\n",
    "        First the site tensor is updated and then the link tensor.\n",
    "\n",
    "        Args:\n",
    "            node_id (str): The identifier of the site to be updated.\n",
    "            next_node_id (str): The other node of the link to be updated.\n",
    "        \"\"\"\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id,\n",
    "                          time_step_factor=0.5)\n",
    "        self._update_link(node_id, next_node_id,\n",
    "                          time_step_factor=0.5)\n",
    "\n",
    "    def forward_sweep(self):\n",
    "        \"\"\"\n",
    "        Perform the forward sweep through the state.\n",
    "        \"\"\"\n",
    "        for i, node_id in enumerate(self.update_path[:-1]):\n",
    "            # Orthogonalize\n",
    "            if i>0:\n",
    "                self._move_orth_and_update_cache_for_path(self.orthogonalization_path[i-1])\n",
    "            # Select Next Node\n",
    "            next_node_id = self.orthogonalization_path[i][0]\n",
    "            # Update\n",
    "            self._update_forward_site_and_link(node_id, next_node_id)\n",
    "\n",
    "    def _final_forward_update(self):\n",
    "        \"\"\"\n",
    "        Perform the final forward update. \n",
    "        \n",
    "        To save some computation, the update is performed with a full time\n",
    "        step. Since the first update backwards occurs on the same node. We\n",
    "        also do not need to update any link tensors.\n",
    "        \"\"\"\n",
    "        node_id = self.update_path[-1]\n",
    "        assert node_id == self.backwards_update_path[0]\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id)\n",
    "\n",
    "    def _update_first_backward_link(self):\n",
    "        \"\"\"\n",
    "        Update the link between the first and second node in the backwards\n",
    "        update path with a half time step.\n",
    "        \n",
    "        We have already updated the first site on the backwards update path\n",
    "        and the link will always be next to it, so the orthogonality center\n",
    "        is already at the correct position.\n",
    "        \"\"\"\n",
    "        next_node_id = self.backwards_update_path[1]\n",
    "        self._update_link(self.state.orthogonality_center_id,\n",
    "                          next_node_id,\n",
    "                          time_step_factor=0.5)\n",
    "\n",
    "    def _normal_backward_update(self, node_id: str,\n",
    "                                update_index: int):\n",
    "        \"\"\"\n",
    "        The normal way to make a backwards update.\n",
    "        \n",
    "        First the site tensor is updated. Then the orthogonality center is\n",
    "        moved, if needed. Finally the link tensor between the new\n",
    "        orthogonality center and the next node is updated. \n",
    "        \n",
    "        Args:\n",
    "            node_id (str): The identifier of the site to be updated.\n",
    "            update_index (int): The index of the update in the backwards\n",
    "                update path.\n",
    "        \"\"\"\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id, time_step_factor=0.5)\n",
    "        new_orth_center = self.backwards_orth_path[update_index-1]\n",
    "        self._move_orth_and_update_cache_for_path(new_orth_center)\n",
    "        next_node_id = self.backwards_update_path[update_index+1]\n",
    "        self._update_link(self.state.orthogonality_center_id,\n",
    "                          next_node_id,\n",
    "                          time_step_factor=0.5)\n",
    "\n",
    "    def _final_backward_update(self):\n",
    "        \"\"\"\n",
    "        Perform the final backward update.\n",
    "        \n",
    "        Since this is the last node that needs updating, no link update is\n",
    "        required afterwards.\n",
    "        \"\"\"\n",
    "        node_id = self.backwards_update_path[-1]\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id, time_step_factor=0.5)\n",
    "\n",
    "    def backward_sweep(self):\n",
    "        \"\"\"\n",
    "        Perform the backward sweep through the state.\n",
    "        \"\"\"\n",
    "        self._update_first_backward_link()\n",
    "        for i, node_id in enumerate(self.backwards_update_path[1:-1]):\n",
    "            self._normal_backward_update(node_id, i+1)\n",
    "        self._final_backward_update()\n",
    "\n",
    "    def run_one_time_step(self):\n",
    "        \"\"\"\n",
    "        Run a single second order time step.\n",
    "        \n",
    "        This mean we run a full forward and a full backward sweep through the\n",
    "        tree.\n",
    "        \"\"\"\n",
    "        self.forward_sweep()\n",
    "        self._final_forward_update()\n",
    "        self.backward_sweep()\n",
    "\n",
    "\n",
    "    def forward_sweep_ex(self):\n",
    "        \"\"\"\n",
    "        Perform the forward sweep through the state.\n",
    "        \"\"\"\n",
    "        for i, node_id in enumerate(self.update_path[:-1]):\n",
    "            # Orthogonalize\n",
    "            if i>0:\n",
    "                self._move_orth_and_update_cache_for_path(self.orthogonalization_path[i-1])\n",
    "            # Select Next Node\n",
    "            next_node_id = self.orthogonalization_path[i][0]\n",
    "            # Update\n",
    "            self._update_forward_site_and_link(node_id, next_node_id)\n",
    "\n",
    "    def run_one_time_step_ex(self):\n",
    "        \"\"\"\n",
    "        Run a single second order time step.\n",
    "        \n",
    "        This mean we run a full forward and a full backward sweep through the\n",
    "        tree.\n",
    "        \"\"\"\n",
    "\n",
    "        self.forward_sweep_ex()\n",
    "        self._final_forward_update()\n",
    "        self.backward_sweep()  \n",
    "    \n",
    "\n",
    "    # EXPANDS with a predefined T3NS\n",
    "    def run_ex(self, evaluation_time: Union[int,\"inf\"] = 1, filepath: str = \"\",\n",
    "            pgbar: bool = True,):\n",
    "        \"\"\"\n",
    "        Runs this time evolution algorithm for the given parameters.\n",
    "\n",
    "        The desired operator expectation values are evaluated and saved.\n",
    "\n",
    "        Args:\n",
    "            evaluation_time (int, optional): The difference in time steps after which\n",
    "                to evaluate the operator expectation values, e.g. for a value of 10\n",
    "                the operators are evaluated at time steps 0,10,20,... If it is set to\n",
    "                \"inf\", the operators are only evaluated at the end of the time.\n",
    "                Defaults to 1.\n",
    "            filepath (str, optional): If results are to be saved in an external file,\n",
    "                the path to that file can be specified here. Defaults to \"\".\n",
    "            pgbar (bool, optional): Toggles the progress bar. Defaults to True.\n",
    "        \"\"\"\n",
    "        should_expand = True\n",
    "        self._init_results(evaluation_time)\n",
    "        assert self._results is not None\n",
    "        tol = self.initial_tol\n",
    "        I = TTNO.Identity(self.state)\n",
    "        t3no , _ = max_two_neighbour_form(self.hamiltonian , self.t3n_dict)\n",
    "\n",
    "        for i in tqdm(range(self.num_time_steps + 1), disable=not pgbar):\n",
    "            ttn_copy_1 = deepcopy(self.state)\n",
    "\n",
    "            I_ex = ttn_copy_1.operator_expectation_value_Lindblad(I)              \n",
    "            if np.abs(np.abs(I_ex) - 1)  > self.norm_tol:\n",
    "                orth_center_id_1 = self.state.root_id\n",
    "                orth_center_id_2 = orth_center_id_1.replace('Site', 'Node')\n",
    "                #self.state = normalize_ttn_Lindblad_3(ttn_copy_1 , orth_center_id_1 , orth_center_id_2) # better than 1 and 4\n",
    "                #self.state = normalize_ttn_Lindblad_1_conj(ttn_copy_1) # better than 1 and 4\n",
    "\n",
    "                update_path_0 = self.update_path[0]\n",
    "                self.state = normalize_ttn_Lindblad_4(ttn_copy_1 , update_path_0)                 \n",
    "                norm = self.state.operator_expectation_value_Lindblad(I)\n",
    "                #print(\"Norm :\" ,norm, np.abs(norm))\n",
    "            else:\n",
    "                self.state = ttn_copy_1  \n",
    "                norm1 = ttn_copy_1.operator_expectation_value_Lindblad(I)\n",
    "                norm2 = contract_ttn_Lindblad(ttn_copy_1)\n",
    "                print(\"Norm1 :\" ,norm1, np.abs(norm1))\n",
    "                print(\"Norm2 :\" ,norm2, np.abs(norm2))\n",
    "\n",
    "            if evaluation_time != \"inf\" and i % evaluation_time == 0 and len(self._results) > 0:\n",
    "                index = i // evaluation_time\n",
    "                current_results = self.evaluate_operators() / norm\n",
    "                print(\"M :\" , current_results[0])\n",
    "                self._results[0:-1, index] = current_results\n",
    "                # Save current time\n",
    "                self._results[-1, index] = i*self.time_step_size  \n",
    "\n",
    "            self._orthogonalize_init(force_new=True)\n",
    "            self.partial_tree_cache = PartialTreeCachDict()\n",
    "            self._init_partial_tree_cache() \n",
    "            self.run_one_time_step_ex() \n",
    "\n",
    "            ########### EXAPNSION ###########\n",
    "            before_ex_total_bond_ttn = self.state.total_bond_dim()\n",
    "            \n",
    "            if (i+1) % (self.expansion_steps+1) == 0 and should_expand:  \n",
    "                ######## T3NS ########\n",
    "                ttn = deepcopy(self.state)\n",
    "                t3n , _  = max_two_neighbour_form(ttn , self.t3n_dict)\n",
    "                \n",
    "                adjust_operator_to_ket(t3no,t3n)\n",
    "                adjust_bra_to_ket(t3n)\n",
    "                before_ex_total_bond_t3ns = t3n.total_bond_dim()\n",
    "\n",
    "                self.SVDParameters = replace(self.SVDParameters, max_bond_dim = t3n.max_bond_dim())\n",
    "                print(\"SVD MAX :\" , self.SVDParameters.max_bond_dim)\n",
    "\n",
    "                print(\"tol :\" , tol)       \n",
    "                state_ex_t3n = expand_subspace(t3n, \n",
    "                                            t3no, \n",
    "                                            self.num_vecs, \n",
    "                                            self.tau, \n",
    "                                            self.SVDParameters, \n",
    "                                            tol, \n",
    "                                            self.Lanczos_threshold, \n",
    "                                            self.k_fraction, \n",
    "                                            self.validity_fraction, \n",
    "                                            self.increase_fraction,\n",
    "                                            self.max_iter,\n",
    "                                            self.KrylovBasisMode)\n",
    "                after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                state_ex_ttn = original_form(state_ex_t3n , self.t3n_dict)\n",
    "                expanded_dim_tot = state_ex_ttn.total_bond_dim() - ttn.total_bond_dim()\n",
    "                if  expanded_dim_tot > self.rel_tot_bond:\n",
    "                    print(\"expanded_dim_tot :\" , expanded_dim_tot)\n",
    "                    A = True\n",
    "                    # tol_prime = tol\n",
    "                    for _ in range(10):\n",
    "                        if A:\n",
    "                            tol *= self.tol_step\n",
    "                            print(\"1) tol\" , tol)                            \n",
    "                            state_ex_t3n_prime = expand_subspace(t3n, \n",
    "                                                                t3no, \n",
    "                                                                self.num_vecs, \n",
    "                                                                self.tau, \n",
    "                                                                self.SVDParameters, \n",
    "                                                                tol, \n",
    "                                                                self.Lanczos_threshold, \n",
    "                                                                self.k_fraction, \n",
    "                                                                self.validity_fraction, \n",
    "                                                                self.increase_fraction,\n",
    "                                                                self.max_iter,\n",
    "                                                                self.KrylovBasisMode)\n",
    "                            after_ex_total_bond_t3ns = state_ex_t3n_prime.total_bond_dim()\n",
    "                            state_ex_ttn = original_form(state_ex_t3n_prime , self.t3n_dict)\n",
    "                            expanded_dim_tot = state_ex_ttn.total_bond_dim() - ttn.total_bond_dim()\n",
    "                            print(\"2) expanded_dim :\" , expanded_dim_tot)\n",
    "                            if expanded_dim_tot < 0:\n",
    "                                state_ex_ttn = ttn\n",
    "                                tol /= self.tol_step\n",
    "                                A = False\n",
    "                            elif expanded_dim_tot < self.rel_tot_bond :  \n",
    "                                A = False  \n",
    "                self._orthogonalize_init(force_new=True)                     \n",
    "\n",
    "                if self.max_bond < state_ex_ttn.total_bond_dim():\n",
    "                    print(self.max_bond , state_ex_ttn.total_bond_dim()) \n",
    "                    state_ex_ttn = ttn\n",
    "                    should_expand = False\n",
    "                    print(\"3\")\n",
    "\n",
    "                if state_ex_ttn.total_bond_dim() - before_ex_total_bond_ttn <= 0:\n",
    "                   state_ex_ttn = ttn\n",
    "                   tol /= self.tol_step\n",
    "                   print(state_ex_ttn.total_bond_dim() , before_ex_total_bond_ttn)\n",
    "                   print(\"4\")      \n",
    "\n",
    "                self.state = state_ex_ttn\n",
    "                after_ex_total_bond_ttn = self.state.total_bond_dim()\n",
    "\n",
    "                expanded_dim_total_bond_ttn = after_ex_total_bond_ttn - before_ex_total_bond_ttn\n",
    "                expanded_dim_total_bond_t3ns = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns\n",
    "\n",
    "                if self.max_bond < after_ex_total_bond_ttn:\n",
    "                    print(\"END :\" , after_ex_total_bond_ttn)\n",
    "                    should_expand = False      \n",
    "                \n",
    "                print(\"expanded_dim T3NS:\" , expanded_dim_total_bond_t3ns)      \n",
    "                print(\"T3NS:\" , before_ex_total_bond_t3ns , \"--->\" , after_ex_total_bond_t3ns)   \n",
    "\n",
    "                print(\"expanded_dim TTN:\" , expanded_dim_total_bond_ttn)\n",
    "                print(\"TTN:\" , before_ex_total_bond_ttn , \"--->\" , after_ex_total_bond_ttn)    \n",
    " \n",
    "            ##################################\n",
    "                 \n",
    "            self.record_bond_dimensions()\n",
    "                    \n",
    "        if evaluation_time == \"inf\":\n",
    "            current_results = self.evaluate_operators()\n",
    "            self._results[0:-1, 0] = current_results\n",
    "            self._results[-1, 0] = i*self.time_step_size\n",
    "        if filepath != \"\":\n",
    "            self.save_results_to_file(filepath)         \n",
    "\n",
    "\n",
    "\n",
    "    # RUN entirly in T3NS form                \n",
    "    def run_ex_t3n(self, evaluation_time: Union[int,\"inf\"] = 1, filepath: str = \"\",\n",
    "            pgbar: bool = True,):\n",
    "        \"\"\"\n",
    "        Runs this time evolution algorithm for the given parameters.\n",
    "\n",
    "        The desired operator expectation values are evaluated and saved.\n",
    "\n",
    "        Args:\n",
    "            evaluation_time (int, optional): The difference in time steps after which\n",
    "                to evaluate the operator expectation values, e.g. for a value of 10\n",
    "                the operators are evaluated at time steps 0,10,20,... If it is set to\n",
    "                \"inf\", the operators are only evaluated at the end of the time.\n",
    "                Defaults to 1.\n",
    "            filepath (str, optional): If results are to be saved in an external file,\n",
    "                the path to that file can be specified here. Defaults to \"\".\n",
    "            pgbar (bool, optional): Toggles the progress bar. Defaults to True.\n",
    "        \"\"\"\n",
    "        self._init_two_neighbour_form() \n",
    "        should_expand = True\n",
    "        self._init_results(evaluation_time)\n",
    "        assert self._results is not None\n",
    "        tol = self.initial_tol\n",
    "        I = TTNO.Identity(self.state)\n",
    "\n",
    "        for i in tqdm(range(self.num_time_steps + 1), disable=not pgbar):\n",
    "            t3n_copy_1 = deepcopy(self.state)\n",
    "\n",
    "            if  self.normalize:\n",
    "                #orth_center_id_1 = self.state.root_id\n",
    "                #orth_center_id_2 = orth_center_id_1.replace('Site', 'Node')\n",
    "                #self.state = normalize_ttn_Lindblad_3_conj(t3n_copy_1 , orth_center_id_1 , orth_center_id_2) # better than 1 and 4\n",
    "                #self._orthogonalize_init(force_new=True)\n",
    "\n",
    "                update_path_0 = self.update_path[0]\n",
    "                self.state = normalize_ttn_Lindblad_4(t3n_copy_1 , update_path_0) \n",
    "                \n",
    "                self.partial_tree_cache = PartialTreeCachDict()\n",
    "                self._init_partial_tree_cache()                 \n",
    "                norm = self.state.operator_expectation_value_Lindblad(I)\n",
    "                #print(\"Norm :\" ,norm, np.abs(norm))\n",
    "            else:\n",
    "                self.state = t3n_copy_1  \n",
    "                norm = t3n_copy_1.operator_expectation_value_Lindblad(I)\n",
    "                #print(\"Norm :\" ,norm, np.abs(norm))\n",
    "\n",
    "            if evaluation_time != \"inf\" and i % evaluation_time == 0 and len(self._results) > 0:\n",
    "                index = i // evaluation_time\n",
    "                current_results = self.evaluate_operators()\n",
    "                #print(\"H :\" , self.evaluate_operators()[0] / norm)\n",
    "                self._results[0:-1, index] = current_results\n",
    "                # Save current time\n",
    "                self._results[-1, index] = i*self.time_step_size  \n",
    "\n",
    "            self.run_one_time_step_ex() \n",
    "\n",
    "            ########### EXAPNSION ###########\n",
    "            before_ex_total_bond_t3ns = self.state.total_bond_dim()\n",
    "            \n",
    "            if (i+1) % (self.expansion_steps+1) == 0 and should_expand:  \n",
    "                \n",
    "                ######## T3NS ########\n",
    "                t3n = deepcopy(self.state)\n",
    "                t3no = deepcopy(self.hamiltonian)\n",
    "                        \n",
    "                adjust_operator_to_ket(t3no,t3n)\n",
    "                adjust_bra_to_ket(t3n)\n",
    "                print(\"tol :\" , tol)   \n",
    "                self.SVDParameters = replace(self.SVDParameters, max_bond_dim = t3n.max_bond_dim())\n",
    "                print(\"max_bond_dim :\" , self.SVDParameters.max_bond_dim)\n",
    "                state_ex_t3n = expand_subspace(t3n, \n",
    "                                            t3no, \n",
    "                                            self.num_vecs, \n",
    "                                            self.tau, \n",
    "                                            self.SVDParameters, \n",
    "                                            tol, \n",
    "                                            self.Lanczos_threshold, \n",
    "                                            self.k_fraction, \n",
    "                                            self.validity_fraction, \n",
    "                                            self.increase_fraction,\n",
    "                                            self.max_iter,\n",
    "                                            self.KrylovBasisMode)\n",
    "                after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                expanded_dim_tot = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns\n",
    "                if expanded_dim_tot <= 0:\n",
    "                    state_ex_t3n = t3n\n",
    "                    tol /= self.tol_step\n",
    "\n",
    "                if  expanded_dim_tot > self.rel_tot_bond:\n",
    "                    print(\"expanded_dim_tot :\" , expanded_dim_tot)\n",
    "                    A = True\n",
    "                    # tol_prime = tol\n",
    "                    for _ in range(10):\n",
    "                        if A:\n",
    "                            tol *= self.tol_step\n",
    "                            print(\"1) tol\" , tol)                            \n",
    "                            state_ex_t3n = expand_subspace(t3n, \n",
    "                                                                t3no, \n",
    "                                                                self.num_vecs, \n",
    "                                                                self.tau, \n",
    "                                                                self.SVDParameters, \n",
    "                                                                tol, \n",
    "                                                                self.Lanczos_threshold, \n",
    "                                                                self.k_fraction, \n",
    "                                                                self.validity_fraction, \n",
    "                                                                self.increase_fraction,\n",
    "                                                                self.max_iter,\n",
    "                                                                self.KrylovBasisMode)\n",
    "                            after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                            expanded_dim_tot = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns\n",
    "\n",
    "                            print(\"2) expanded_dim :\" , expanded_dim_tot)\n",
    "                            if expanded_dim_tot <= 0:\n",
    "                                state_ex_t3n = t3n\n",
    "                                tol /= self.tol_step\n",
    "                                A = False\n",
    "                            elif expanded_dim_tot < self.rel_tot_bond :  \n",
    "                                A = False                \n",
    "\n",
    "                if self.max_bond < state_ex_t3n.total_bond_dim():\n",
    "                    print(self.max_bond , state_ex_t3n.total_bond_dim()) \n",
    "                    state_ex_t3n = t3n\n",
    "                    should_expand = False\n",
    "                    print(\"3\") \n",
    "\n",
    "                self.state = state_ex_t3n\n",
    "                self._orthogonalize_init(force_new=True)\n",
    "\n",
    "                after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                expanded_dim_tot = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns \n",
    "                                   \n",
    "                print(\"expanded_dim T3NS:\" , expanded_dim_tot)      \n",
    "                print(\"T3NS:\" , before_ex_total_bond_t3ns , \"--->\" , after_ex_total_bond_t3ns)      \n",
    " \n",
    "            ##################################\n",
    "                 \n",
    "            self.record_bond_dimensions()\n",
    "                    \n",
    "        if evaluation_time == \"inf\":\n",
    "            current_results = self.evaluate_operators()\n",
    "            self._results[0:-1, 0] = current_results\n",
    "            self._results[-1, 0] = i*self.time_step_size\n",
    "        if filepath != \"\":\n",
    "            self.save_results_to_file(filepath)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import List, Union\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from dataclasses import replace\n",
    "from ...operators.tensorproduct import TensorProduct\n",
    "from ...ttno.ttno_class import TTNO\n",
    "from ...ttns import (TreeTensorNetworkState , \n",
    "                     normalize_ttn_Lindblad_1 , \n",
    "                        normalize_ttn_Lindblad_1_conj ,\n",
    "                     normalize_ttn_Lindblad_3 , \n",
    "                        normalize_ttn_Lindblad_3_conj ,\n",
    "                     normalize_ttn_Lindblad_4 , \n",
    "                     normalize_ttn_Lindblad_5,\n",
    "                        normalize_ttn_Lindblad_5_conj,\n",
    "                     normalize_ttn_Lindblad_XX ,  )\n",
    "from ..ttn_time_evolution import TTNTimeEvolutionConfig\n",
    "from ..Subspace_expansion import expand_subspace , KrylovBasisMode , max_two_neighbour_form , original_form\n",
    "from ...util.tensor_splitting import SplitMode , SVDParameters\n",
    "from ...core.canonical_form import adjust_ttn1_structure_to_ttn2 , adjust_ttno_structure_to_ttn\n",
    "from pytreenet.contractions.state_operator_contraction import adjust_operator_to_ket , adjust_bra_to_ket\n",
    "from pytreenet.contractions.state_state_contraction import contract_ttn_Lindblad\n",
    "from .onesitetdvp import OneSiteTDVP\n",
    "from ...contractions.tree_cach_dict import PartialTreeCachDict\n",
    "from ...time_evolution.time_evo_util.update_path import TDVPUpdatePathFinder\n",
    "\n",
    "                       \n",
    "\n",
    "\n",
    "class SecondOrderOneSiteTDVP(OneSiteTDVP):\n",
    "    \"\"\"\n",
    "    The first order one site TDVP algorithm.\n",
    "\n",
    "    This means we have second order Trotter splitting for the time evolution:\n",
    "      exp(At+Bt) approx exp(At/2)*exp(Bt/2)*exp(Bt/2)*exp(At/2)\n",
    "\n",
    "    Has the same attributes as the TDVP-Algorithm clas with two additions.\n",
    "\n",
    "    Attributes:\n",
    "        backwards_update_path (List[str]): The update path that traverses\n",
    "            backwards.\n",
    "        backwards_orth_path (List[List[str]]): The orthogonalisation paths for\n",
    "            the backwards run.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 initial_state: TreeTensorNetworkState,\n",
    "                 hamiltonian: TTNO, \n",
    "                 time_step_size: float, \n",
    "                 final_time: float,\n",
    "                 operators: Union[TensorProduct, List[TensorProduct]],\n",
    "\n",
    "                 num_vecs: int , \n",
    "                 tau: float, \n",
    "                 SVDParameters : SVDParameters,\n",
    "                 expansion_steps: int = 10,\n",
    "                 t3n_dict: dict = None,\n",
    "\n",
    "                 Lanczos_threshold : float = 10,\n",
    "                 k_fraction : float = 0.6, \n",
    "                 validity_fraction : float = 0.8, \n",
    "                 increase_fraction : float = 0.3, \n",
    "                 max_iter : int = 10,  \n",
    "\n",
    "                 initial_tol: float = 1e-20,\n",
    "                 tol_step: float = 10, \n",
    "                 rel_tot_bond : int = 30,\n",
    "                 max_bond: int = 100,\n",
    "                 KrylovBasisMode : KrylovBasisMode = KrylovBasisMode.apply_ham,                  \n",
    "                 config: Union[TTNTimeEvolutionConfig,None] = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the second order one site TDVP algorithm.\n",
    "\n",
    "        Args:\n",
    "            initial_state (TreeTensorNetworkState): The initial state of the\n",
    "                system.\n",
    "            hamiltonian (TTNO): The Hamiltonian of the system.\n",
    "            time_step_size (float): The time step size.\n",
    "            final_time (float): The final time of the evolution.\n",
    "            operators (Union[TensorProduct, List[TensorProduct]]): The operators\n",
    "                for which the expectation values are calculated.\n",
    "            config (Union[TTNTimeEvolutionConfig,None], optional): The time\n",
    "                evolution configuration. Defaults to None.\n",
    "        \"\"\"\n",
    "        super().__init__(initial_state, hamiltonian,\n",
    "                         time_step_size, final_time, operators, num_vecs, \n",
    "                         tau,\n",
    "                         SVDParameters,\n",
    "                         expansion_steps,\n",
    "                         initial_tol,\n",
    "                         tol_step,\n",
    "                         rel_tot_bond,\n",
    "                         max_bond,\n",
    "                         KrylovBasisMode,  \n",
    "                         config)\n",
    "        self.t3n_dict = t3n_dict\n",
    "        self.Lanczos_threshold = Lanczos_threshold\n",
    "        self.k_fraction = k_fraction\n",
    "        self.validity_fraction = validity_fraction\n",
    "        self.increase_fraction = increase_fraction\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "        if self.T3NS :\n",
    "           self._init_two_neighbour_form() \n",
    "        else:\n",
    "            self.adjust_to_initial_structure()\n",
    "            self.update_path = TDVPUpdatePathFinder(self.state).find_path()\n",
    "            self.orthogonalization_path = self._find_tdvp_orthogonalization_path(self.update_path) \n",
    "            self.backwards_update_path = self._init_second_order_update_path()\n",
    "            self.backwards_orth_path = self._init_second_order_orth_path() \n",
    "            self._orthogonalize_init()\n",
    "            self.partial_tree_cache = PartialTreeCachDict()\n",
    "            self._init_partial_tree_cache()           \n",
    "\n",
    "    def _init_two_neighbour_form(self):\n",
    "        \"\"\"\n",
    "        Transform the state, Hamiltonian and operators into the max two neighbour form.\n",
    "        \"\"\"\n",
    "        self.adjust_to_initial_structure()\n",
    "        self.state , dict1 = max_two_neighbour_form(self.state)\n",
    "        self.hamiltonian , _ = max_two_neighbour_form(self.hamiltonian , dict1)\n",
    "        list = []\n",
    "        for operators in self.operators: \n",
    "            operator , _ = max_two_neighbour_form(operators,dict1)\n",
    "            list.append(operator)\n",
    "        self.operators = list\n",
    "\n",
    "        self.adjust_to_initial_structure()\n",
    "        self.update_path = TDVPUpdatePathFinder(self.state).find_path()\n",
    "        self.orthogonalization_path = self._find_tdvp_orthogonalization_path(self.update_path) \n",
    "        self.backwards_update_path = self._init_second_order_update_path()\n",
    "        self.backwards_orth_path = self._init_second_order_orth_path() \n",
    "        self.two_neighbour_form_dict = dict1\n",
    "        self._orthogonalize_init()\n",
    "        self.partial_tree_cache = PartialTreeCachDict()\n",
    "        self._init_partial_tree_cache()\n",
    "        \n",
    "    \n",
    "    def _init_second_order_update_path(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Find the update path that traverses backwards.\n",
    "        \"\"\"\n",
    "        return list(reversed(self.update_path))\n",
    "\n",
    "    def _init_second_order_orth_path(self) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Find the orthogonalisation paths for the backwards run.\n",
    "        \"\"\"\n",
    "        back_orthogonalization_path = []\n",
    "        for i, node_id in enumerate(self.backwards_update_path[1:-1]):\n",
    "            current_path = self.state.path_from_to(node_id,\n",
    "                                                   self.backwards_update_path[i+2])\n",
    "            current_path = current_path[:-1]\n",
    "            back_orthogonalization_path.append(current_path)\n",
    "        back_orthogonalization_path.append([self.backwards_update_path[-1]])\n",
    "        return back_orthogonalization_path\n",
    "\n",
    "    def _update_forward_site_and_link(self, node_id: str,\n",
    "                                      next_node_id: str):\n",
    "        \"\"\"\n",
    "        Run the forward update with half time step.\n",
    "\n",
    "        First the site tensor is updated and then the link tensor.\n",
    "\n",
    "        Args:\n",
    "            node_id (str): The identifier of the site to be updated.\n",
    "            next_node_id (str): The other node of the link to be updated.\n",
    "        \"\"\"\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id,\n",
    "                          time_step_factor=0.5)\n",
    "        self._update_link(node_id, next_node_id,\n",
    "                          time_step_factor=0.5)\n",
    "\n",
    "    def forward_sweep(self):\n",
    "        \"\"\"\n",
    "        Perform the forward sweep through the state.\n",
    "        \"\"\"\n",
    "        for i, node_id in enumerate(self.update_path[:-1]):\n",
    "            # Orthogonalize\n",
    "            if i>0:\n",
    "                self._move_orth_and_update_cache_for_path(self.orthogonalization_path[i-1])\n",
    "            # Select Next Node\n",
    "            next_node_id = self.orthogonalization_path[i][0]\n",
    "            # Update\n",
    "            self._update_forward_site_and_link(node_id, next_node_id)\n",
    "\n",
    "    def _final_forward_update(self):\n",
    "        \"\"\"\n",
    "        Perform the final forward update. \n",
    "        \n",
    "        To save some computation, the update is performed with a full time\n",
    "        step. Since the first update backwards occurs on the same node. We\n",
    "        also do not need to update any link tensors.\n",
    "        \"\"\"\n",
    "        node_id = self.update_path[-1]\n",
    "        assert node_id == self.backwards_update_path[0]\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id)\n",
    "\n",
    "    def _update_first_backward_link(self):\n",
    "        \"\"\"\n",
    "        Update the link between the first and second node in the backwards\n",
    "        update path with a half time step.\n",
    "        \n",
    "        We have already updated the first site on the backwards update path\n",
    "        and the link will always be next to it, so the orthogonality center\n",
    "        is already at the correct position.\n",
    "        \"\"\"\n",
    "        next_node_id = self.backwards_update_path[1]\n",
    "        self._update_link(self.state.orthogonality_center_id,\n",
    "                          next_node_id,\n",
    "                          time_step_factor=0.5)\n",
    "\n",
    "    def _normal_backward_update(self, node_id: str,\n",
    "                                update_index: int):\n",
    "        \"\"\"\n",
    "        The normal way to make a backwards update.\n",
    "        \n",
    "        First the site tensor is updated. Then the orthogonality center is\n",
    "        moved, if needed. Finally the link tensor between the new\n",
    "        orthogonality center and the next node is updated. \n",
    "        \n",
    "        Args:\n",
    "            node_id (str): The identifier of the site to be updated.\n",
    "            update_index (int): The index of the update in the backwards\n",
    "                update path.\n",
    "        \"\"\"\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id, time_step_factor=0.5)\n",
    "        new_orth_center = self.backwards_orth_path[update_index-1]\n",
    "        self._move_orth_and_update_cache_for_path(new_orth_center)\n",
    "        next_node_id = self.backwards_update_path[update_index+1]\n",
    "        self._update_link(self.state.orthogonality_center_id,\n",
    "                          next_node_id,\n",
    "                          time_step_factor=0.5)\n",
    "\n",
    "    def _final_backward_update(self):\n",
    "        \"\"\"\n",
    "        Perform the final backward update.\n",
    "        \n",
    "        Since this is the last node that needs updating, no link update is\n",
    "        required afterwards.\n",
    "        \"\"\"\n",
    "        node_id = self.backwards_update_path[-1]\n",
    "        assert self.state.orthogonality_center_id == node_id\n",
    "        self._update_site(node_id, time_step_factor=0.5)\n",
    "\n",
    "    def backward_sweep(self):\n",
    "        \"\"\"\n",
    "        Perform the backward sweep through the state.\n",
    "        \"\"\"\n",
    "        self._update_first_backward_link()\n",
    "        for i, node_id in enumerate(self.backwards_update_path[1:-1]):\n",
    "            self._normal_backward_update(node_id, i+1)\n",
    "        self._final_backward_update()\n",
    "\n",
    "    def forward_sweep_ex(self):\n",
    "        \"\"\"\n",
    "        Perform the forward sweep through the state.\n",
    "        \"\"\"\n",
    "        for i, node_id in enumerate(self.update_path[:-1]):\n",
    "            # Orthogonalize\n",
    "            if i>0:\n",
    "                self._move_orth_and_update_cache_for_path(self.orthogonalization_path[i-1])\n",
    "            # Select Next Node\n",
    "            next_node_id = self.orthogonalization_path[i][0]\n",
    "            # Update\n",
    "            self._update_forward_site_and_link(node_id, next_node_id)\n",
    "\n",
    "    def create_temp_copy(self):\n",
    "        \"\"\"\n",
    "        Creates a temporary copy of the object with deep copies of state and cache.\n",
    "        \"\"\"\n",
    "        temp_self = copy.copy(self)\n",
    "        temp_self.state = copy.deepcopy(self.state)\n",
    "        return temp_self\n",
    "\n",
    "    def run_one_time_step(self):\n",
    "        # remove self._orthogonalize_init() and self.partial_tree_cache in TDVPAlgorithm\n",
    "        temp_self = self.create_temp_copy()\n",
    "        temp_self._orthogonalize_init()\n",
    "        temp_self.adjust_to_initial_structure()\n",
    "        temp_self._init_partial_tree_cache()\n",
    "\n",
    "        temp_self.forward_sweep()\n",
    "        temp_self._final_forward_update()\n",
    "        temp_self.backward_sweep()\n",
    "        temp_self.adjust_to_initial_structure()\n",
    "\n",
    "        orth_center_id_1 = temp_self.state.root_id\n",
    "        orth_center_id_2 = orth_center_id_1.replace('Site', 'Node')\n",
    "        temp_self.state = normalize_ttn_Lindblad_3_conj(self.state , orth_center_id_1 , orth_center_id_2 )\n",
    "        self.state = temp_self.state\n",
    "        self.adjust_to_initial_structure() \n",
    "    \n",
    "\n",
    "    # EXPANDS with a predefined T3NS\n",
    "    def run_ex(self, evaluation_time: Union[int,\"inf\"] = 1, filepath: str = \"\",\n",
    "            pgbar: bool = True,):\n",
    "        \"\"\"\n",
    "        Runs this time evolution algorithm for the given parameters.\n",
    "\n",
    "        The desired operator expectation values are evaluated and saved.\n",
    "\n",
    "        Args:\n",
    "            evaluation_time (int, optional): The difference in time steps after which\n",
    "                to evaluate the operator expectation values, e.g. for a value of 10\n",
    "                the operators are evaluated at time steps 0,10,20,... If it is set to\n",
    "                \"inf\", the operators are only evaluated at the end of the time.\n",
    "                Defaults to 1.\n",
    "            filepath (str, optional): If results are to be saved in an external file,\n",
    "                the path to that file can be specified here. Defaults to \"\".\n",
    "            pgbar (bool, optional): Toggles the progress bar. Defaults to True.\n",
    "        \"\"\"\n",
    "        should_expand = True\n",
    "        self._init_results(evaluation_time)\n",
    "        assert self._results is not None\n",
    "        tol = self.initial_tol\n",
    "        I = TTNO.Identity(self.state)\n",
    "        t3no , _ = max_two_neighbour_form(self.hamiltonian , self.t3n_dict)\n",
    "\n",
    "        for i in tqdm(range(self.num_time_steps + 1), disable=not pgbar):\n",
    "            if evaluation_time != \"inf\" and i % evaluation_time == 0 and len(self._results) > 0:\n",
    "                index = i // evaluation_time\n",
    "                current_results = self.evaluate_operators()\n",
    "                print(\"N :\" , current_results[0] , np.abs(current_results[0]))\n",
    "                self._results[0:-1, index] = current_results\n",
    "                # Save current time\n",
    "                self._results[-1, index] = i*self.time_step_size  \n",
    "\n",
    "            self.run_one_time_step() \n",
    "\n",
    "            ########### EXAPNSION ###########\n",
    "            before_ex_total_bond_ttn = self.state.total_bond_dim()\n",
    "            \n",
    "            if (i+1) % (self.expansion_steps+1) == 0 and should_expand:  \n",
    "                ######## T3NS ########\n",
    "                ttn = copy.deepcopy(self.state)\n",
    "                t3n , _  = max_two_neighbour_form(ttn , self.t3n_dict)\n",
    "                \n",
    "                adjust_operator_to_ket(t3no,t3n)\n",
    "                adjust_bra_to_ket(t3n)\n",
    "                before_ex_total_bond_t3ns = t3n.total_bond_dim()\n",
    "\n",
    "                self.SVDParameters = replace(self.SVDParameters, max_bond_dim = t3n.max_bond_dim())\n",
    "                print(\"SVD MAX :\" , self.SVDParameters.max_bond_dim)\n",
    "\n",
    "                print(\"tol :\" , tol)       \n",
    "                state_ex_t3n = expand_subspace(t3n, \n",
    "                                            t3no, \n",
    "                                            self.num_vecs, \n",
    "                                            self.tau, \n",
    "                                            self.SVDParameters, \n",
    "                                            tol, \n",
    "                                            self.Lanczos_threshold, \n",
    "                                            self.k_fraction, \n",
    "                                            self.validity_fraction, \n",
    "                                            self.increase_fraction,\n",
    "                                            self.max_iter,\n",
    "                                            self.KrylovBasisMode)\n",
    "                after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                state_ex_ttn = original_form(state_ex_t3n , self.t3n_dict)\n",
    "                expanded_dim_tot = state_ex_ttn.total_bond_dim() - ttn.total_bond_dim()\n",
    "                if  expanded_dim_tot > self.rel_tot_bond:\n",
    "                    print(\"expanded_dim_tot :\" , expanded_dim_tot)\n",
    "                    A = True\n",
    "                    # tol_prime = tol\n",
    "                    for _ in range(10):\n",
    "                        if A:\n",
    "                            tol *= self.tol_step\n",
    "                            print(\"1) tol\" , tol)                            \n",
    "                            state_ex_t3n_prime = expand_subspace(t3n, \n",
    "                                                                t3no, \n",
    "                                                                self.num_vecs, \n",
    "                                                                self.tau, \n",
    "                                                                self.SVDParameters, \n",
    "                                                                tol, \n",
    "                                                                self.Lanczos_threshold, \n",
    "                                                                self.k_fraction, \n",
    "                                                                self.validity_fraction, \n",
    "                                                                self.increase_fraction,\n",
    "                                                                self.max_iter,\n",
    "                                                                self.KrylovBasisMode)\n",
    "                            after_ex_total_bond_t3ns = state_ex_t3n_prime.total_bond_dim()\n",
    "                            state_ex_ttn = original_form(state_ex_t3n_prime , self.t3n_dict)\n",
    "                            expanded_dim_tot = state_ex_ttn.total_bond_dim() - ttn.total_bond_dim()\n",
    "                            print(\"2) expanded_dim :\" , expanded_dim_tot)\n",
    "                            if expanded_dim_tot < 0:\n",
    "                                state_ex_ttn = ttn\n",
    "                                tol /= self.tol_step\n",
    "                                A = False\n",
    "                            elif expanded_dim_tot < self.rel_tot_bond :  \n",
    "                                A = False  \n",
    "                self.state = normalize_ttn_Lindblad_1_conj(self.state)\n",
    "                self.adjust_to_initial_structure()                 \n",
    "                #self._orthogonalize_init(force_new=True)                     \n",
    "\n",
    "                if self.max_bond < state_ex_ttn.total_bond_dim():\n",
    "                    print(self.max_bond , state_ex_ttn.total_bond_dim()) \n",
    "                    state_ex_ttn = ttn\n",
    "                    should_expand = False\n",
    "                    print(\"3\")\n",
    "\n",
    "                if state_ex_ttn.total_bond_dim() - before_ex_total_bond_ttn <= 0:\n",
    "                   state_ex_ttn = ttn\n",
    "                   tol /= self.tol_step\n",
    "                   print(state_ex_ttn.total_bond_dim() , before_ex_total_bond_ttn)\n",
    "                   print(\"4\")      \n",
    "\n",
    "                self.state = state_ex_ttn\n",
    "                after_ex_total_bond_ttn = self.state.total_bond_dim()\n",
    "\n",
    "                expanded_dim_total_bond_ttn = after_ex_total_bond_ttn - before_ex_total_bond_ttn\n",
    "                expanded_dim_total_bond_t3ns = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns\n",
    "\n",
    "                if self.max_bond < after_ex_total_bond_ttn:\n",
    "                    print(\"END :\" , after_ex_total_bond_ttn)\n",
    "                    should_expand = False      \n",
    "                \n",
    "                print(\"expanded_dim T3NS:\" , expanded_dim_total_bond_t3ns)      \n",
    "                print(\"T3NS:\" , before_ex_total_bond_t3ns , \"--->\" , after_ex_total_bond_t3ns)   \n",
    "\n",
    "                print(\"expanded_dim TTN:\" , expanded_dim_total_bond_ttn)\n",
    "                print(\"TTN:\" , before_ex_total_bond_ttn , \"--->\" , after_ex_total_bond_ttn)    \n",
    " \n",
    "            ##################################\n",
    "                 \n",
    "            self.record_bond_dimensions()\n",
    "                    \n",
    "        if evaluation_time == \"inf\":\n",
    "            current_results = self.evaluate_operators()\n",
    "            self._results[0:-1, 0] = current_results\n",
    "            self._results[-1, 0] = i*self.time_step_size\n",
    "        if filepath != \"\":\n",
    "            self.save_results_to_file(filepath)         \n",
    "\n",
    "\n",
    "\n",
    "    # RUN entirly in T3NS form                \n",
    "    def run_ex_t3n(self, evaluation_time: Union[int,\"inf\"] = 1, filepath: str = \"\",\n",
    "            pgbar: bool = True,):\n",
    "        \"\"\"\n",
    "        Runs this time evolution algorithm for the given parameters.\n",
    "\n",
    "        The desired operator expectation values are evaluated and saved.\n",
    "\n",
    "        Args:\n",
    "            evaluation_time (int, optional): The difference in time steps after which\n",
    "                to evaluate the operator expectation values, e.g. for a value of 10\n",
    "                the operators are evaluated at time steps 0,10,20,... If it is set to\n",
    "                \"inf\", the operators are only evaluated at the end of the time.\n",
    "                Defaults to 1.\n",
    "            filepath (str, optional): If results are to be saved in an external file,\n",
    "                the path to that file can be specified here. Defaults to \"\".\n",
    "            pgbar (bool, optional): Toggles the progress bar. Defaults to True.\n",
    "        \"\"\"\n",
    "        self._init_two_neighbour_form() \n",
    "        should_expand = True\n",
    "        self._init_results(evaluation_time)\n",
    "        assert self._results is not None\n",
    "        tol = self.initial_tol\n",
    "        I = TTNO.Identity(self.state)\n",
    "\n",
    "        for i in tqdm(range(self.num_time_steps + 1), disable=not pgbar):\n",
    "            t3n_copy_1 = copy.deepcopy(self.state)\n",
    "\n",
    "            if  self.normalize:\n",
    "                #orth_center_id_1 = self.state.root_id\n",
    "                #orth_center_id_2 = orth_center_id_1.replace('Site', 'Node')\n",
    "                #self.state = normalize_ttn_Lindblad_3_conj(t3n_copy_1 , orth_center_id_1 , orth_center_id_2) # better than 1 and 4\n",
    "                #self._orthogonalize_init(force_new=True)\n",
    "\n",
    "                update_path_0 = self.update_path[0]\n",
    "                self.state = normalize_ttn_Lindblad_4(t3n_copy_1 , update_path_0) \n",
    "                \n",
    "                self.partial_tree_cache = PartialTreeCachDict()\n",
    "                self._init_partial_tree_cache()                 \n",
    "                norm = self.state.operator_expectation_value_Lindblad(I)\n",
    "                #print(\"Norm :\" ,norm, np.abs(norm))\n",
    "            else:\n",
    "                self.state = t3n_copy_1  \n",
    "                norm = t3n_copy_1.operator_expectation_value_Lindblad(I)\n",
    "                #print(\"Norm :\" ,norm, np.abs(norm))\n",
    "\n",
    "            if evaluation_time != \"inf\" and i % evaluation_time == 0 and len(self._results) > 0:\n",
    "                index = i // evaluation_time\n",
    "                current_results = self.evaluate_operators()\n",
    "                #print(\"H :\" , self.evaluate_operators()[0] / norm)\n",
    "                self._results[0:-1, index] = current_results\n",
    "                # Save current time\n",
    "                self._results[-1, index] = i*self.time_step_size  \n",
    "\n",
    "            self.run_one_time_step_ex() \n",
    "\n",
    "            ########### EXAPNSION ###########\n",
    "            before_ex_total_bond_t3ns = self.state.total_bond_dim()\n",
    "            \n",
    "            if (i+1) % (self.expansion_steps+1) == 0 and should_expand:  \n",
    "                \n",
    "                ######## T3NS ########\n",
    "                t3n = copy.deepcopy(self.state)\n",
    "                t3no = copy.deepcopy(self.hamiltonian)\n",
    "                        \n",
    "                adjust_operator_to_ket(t3no,t3n)\n",
    "                adjust_bra_to_ket(t3n)\n",
    "                print(\"tol :\" , tol)   \n",
    "                self.SVDParameters = replace(self.SVDParameters, max_bond_dim = t3n.max_bond_dim())\n",
    "                print(\"max_bond_dim :\" , self.SVDParameters.max_bond_dim)\n",
    "                state_ex_t3n = expand_subspace(t3n, \n",
    "                                            t3no, \n",
    "                                            self.num_vecs, \n",
    "                                            self.tau, \n",
    "                                            self.SVDParameters, \n",
    "                                            tol, \n",
    "                                            self.Lanczos_threshold, \n",
    "                                            self.k_fraction, \n",
    "                                            self.validity_fraction, \n",
    "                                            self.increase_fraction,\n",
    "                                            self.max_iter,\n",
    "                                            self.KrylovBasisMode)\n",
    "                after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                expanded_dim_tot = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns\n",
    "                if expanded_dim_tot <= 0:\n",
    "                    state_ex_t3n = t3n\n",
    "                    tol /= self.tol_step\n",
    "\n",
    "                if  expanded_dim_tot > self.rel_tot_bond:\n",
    "                    print(\"expanded_dim_tot :\" , expanded_dim_tot)\n",
    "                    A = True\n",
    "                    # tol_prime = tol\n",
    "                    for _ in range(10):\n",
    "                        if A:\n",
    "                            tol *= self.tol_step\n",
    "                            print(\"1) tol\" , tol)                            \n",
    "                            state_ex_t3n = expand_subspace(t3n, \n",
    "                                                                t3no, \n",
    "                                                                self.num_vecs, \n",
    "                                                                self.tau, \n",
    "                                                                self.SVDParameters, \n",
    "                                                                tol, \n",
    "                                                                self.Lanczos_threshold, \n",
    "                                                                self.k_fraction, \n",
    "                                                                self.validity_fraction, \n",
    "                                                                self.increase_fraction,\n",
    "                                                                self.max_iter,\n",
    "                                                                self.KrylovBasisMode)\n",
    "                            after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                            expanded_dim_tot = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns\n",
    "\n",
    "                            print(\"2) expanded_dim :\" , expanded_dim_tot)\n",
    "                            if expanded_dim_tot <= 0:\n",
    "                                state_ex_t3n = t3n\n",
    "                                tol /= self.tol_step\n",
    "                                A = False\n",
    "                            elif expanded_dim_tot < self.rel_tot_bond :  \n",
    "                                A = False                \n",
    "\n",
    "                if self.max_bond < state_ex_t3n.total_bond_dim():\n",
    "                    print(self.max_bond , state_ex_t3n.total_bond_dim()) \n",
    "                    state_ex_t3n = t3n\n",
    "                    should_expand = False\n",
    "                    print(\"3\") \n",
    "\n",
    "                self.state = state_ex_t3n\n",
    "                self._orthogonalize_init(force_new=True)\n",
    "\n",
    "                after_ex_total_bond_t3ns = state_ex_t3n.total_bond_dim()\n",
    "                expanded_dim_tot = after_ex_total_bond_t3ns - before_ex_total_bond_t3ns \n",
    "                                   \n",
    "                print(\"expanded_dim T3NS:\" , expanded_dim_tot)      \n",
    "                print(\"T3NS:\" , before_ex_total_bond_t3ns , \"--->\" , after_ex_total_bond_t3ns)      \n",
    " \n",
    "            ##################################\n",
    "                 \n",
    "            self.record_bond_dimensions()\n",
    "                    \n",
    "        if evaluation_time == \"inf\":\n",
    "            current_results = self.evaluate_operators()\n",
    "            self._results[0:-1, 0] = current_results\n",
    "            self._results[-1, 0] = i*self.time_step_size\n",
    "        if filepath != \"\":\n",
    "            self.save_results_to_file(filepath)   \n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
