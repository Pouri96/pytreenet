{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytreenet as ptn\n",
    "from copy import deepcopy\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First did it like this, but I guess completely_contract_tree is more \n",
    "costly that moving the canoical center. I wonder why the results are\n",
    "not same!\n",
    "\"\"\"\n",
    "\n",
    "def reduced_density_matrix(ttn: ptn.TreeTensorNetwork ,node_id : str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the reduced density matrix of a node in a tree tensor network.\n",
    "    Args :\n",
    "        ttn: Tensor\n",
    "        node_id: str\n",
    "    Returns :\n",
    "        pho : Tensor\n",
    "    \"\"\"\n",
    "    pho , order = density_tensor(ttn)\n",
    "    dim = pho.ndim\n",
    "    for i in range(len(order)):\n",
    "        if order[i] == node_id:\n",
    "            count = i\n",
    "    for i in range(count):\n",
    "        pho = np.trace(pho, axis1 = 0, axis2 = pho.ndim//2)\n",
    "    for i in range(count +1 , dim//2):\n",
    "        pho = np.trace(pho, axis1 = 1, axis2 = 1 + pho.ndim//2)\n",
    "    return pho\n",
    "\n",
    "def density_tensor(ttn: ptn.TreeTensorNetwork) -> (np.ndarray, List[str]):\n",
    "    \"\"\"\n",
    "    Computes the density tensor of a tree tensor network.\n",
    "    Args :\n",
    "        ttn: Tensor\n",
    "    Returns :\n",
    "        density tensor : Tensor , \n",
    "        order : List[str]\n",
    "        # order of legs =  [out_1, out_2, ..., out_n, in_1, in_2, ..., in_n] \n",
    "    \"\"\"    \n",
    "    ttn = normalize_ttn(ttn)\n",
    "    ttn_cct = deepcopy(ttn)\n",
    "    tensor , order = ttn_cct.completely_contract_tree()\n",
    "\n",
    "    ket = tensor\n",
    "    bra = tensor.conj()\n",
    "    ket = ket.reshape(ket.shape + (1,))\n",
    "    bra = bra.reshape(bra.shape + (1,))\n",
    "\n",
    "    return  np.tensordot(bra,ket,axes=([-1],[-1])) , order\n",
    "\n",
    "\"\"\"\"\n",
    "I wonder why the results are not same!\n",
    "\"\"\"\n",
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    " # pho , order = density_tensor(ttn) \n",
    "# verryyy costly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     leg_dict \u001b[38;5;241m=\u001b[39m {order[i] : i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(order))}\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ptn\u001b[38;5;241m.\u001b[39mTTNO\u001b[38;5;241m.\u001b[39mfrom_tensor(ttn, tensor, leg_dict)\n\u001b[1;32m----> 6\u001b[0m pho \u001b[38;5;241m=\u001b[39m density_ttno(\u001b[43mmps\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mps' is not defined"
     ]
    }
   ],
   "source": [
    "def density_ttno(ttn):\n",
    "    tensor , order = density_tensor(ttn)\n",
    "    leg_dict = {order[i] : i for i in range(len(order))}\n",
    "    return ptn.TTNO.from_tensor(ttn, tensor, leg_dict)\n",
    "\n",
    "pho = density_ttno(mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttno_trace(pho):\n",
    "    ttno_cct = deepcopy(pho)\n",
    "    ttno_cct = ttno_cct.completely_contract_tree()[0] \n",
    "    for _ in range(ttno_cct.ndim//2):\n",
    "        ttno_cct = np.trace(ttno_cct, axis1 = 0, axis2 = 1)\n",
    "    return ttno_cct\n",
    "\n",
    "ttno_trace(pho[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union, Any, Dict\n",
    "from pytreenet import TDVPUpdatePathFinder\n",
    "from pytreenet import compute_transfer_tensor\n",
    "from pytreenet import SplitMode\n",
    "\n",
    "def move_orth_for_path(ttn,path: List[str]):\n",
    "        if len(path) == 0:\n",
    "            return\n",
    "        assert ttn.orthogonality_center_id == path[0]\n",
    "        for i, node_id in enumerate(path[1:]):\n",
    "            ttn.move_orthogonalization_center(node_id,mode=SplitMode.KEEP)\n",
    "                        \n",
    "def reduced_density(ttn): \n",
    "    update_path = TDVPUpdatePathFinder(ttn).find_path()\n",
    "    ttn.canonical_form(update_path[0],mode=SplitMode.KEEP)\n",
    "\n",
    "    orthogonalization_path = []\n",
    "    for i in range(len(update_path)-1):\n",
    "        sub_path = ttn.path_from_to(update_path[i], update_path[i+1])\n",
    "        orthogonalization_path.append(sub_path[1::])\n",
    "\n",
    "    dict = {}\n",
    "    for i, node_id in enumerate(update_path):\n",
    "        contracted_legs = tuple(range(ttn.tensors[node_id].ndim - 1 )) \n",
    "        if i == len(update_path)-1:\n",
    "            reduced_density = compute_transfer_tensor(ttn.tensors[node_id], contracted_legs)        \n",
    "            dict[node_id] = reduced_density\n",
    "        elif i == 0:\n",
    "            reduced_density = compute_transfer_tensor(ttn.tensors[node_id], contracted_legs)        \n",
    "            dict[node_id] = reduced_density\n",
    "            next_node_id = orthogonalization_path[0][0]\n",
    "            move_orth_for_path(ttn,[node_id, next_node_id])\n",
    "        else:\n",
    "            current_orth_path = orthogonalization_path[i-1]\n",
    "            move_orth_for_path(ttn,current_orth_path)\n",
    "            reduced_density = compute_transfer_tensor(ttn.tensors[node_id], contracted_legs)        \n",
    "            dict[node_id] = reduced_density\n",
    "            next_node_id = orthogonalization_path[i][0]\n",
    "            move_orth_for_path(ttn,[node_id, next_node_id])\n",
    "    return dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonalize_against(ttn1 , ttn2):\n",
    "    for i in range(len(ttn1.nodes)):\n",
    "        a = ttn1.tensors[f\"site{i}\"]\n",
    "        b = deepcopy(ttn2.tensors[f\"site{i}\"])\n",
    "        b = normalize_tensor(b)\n",
    "        indices = tuple(range(b.ndim))\n",
    "        prod = np.tensordot(b.conj(), a , axes = (indices,indices) )\n",
    "        a = a - b * prod\n",
    "        a = a / np.sqrt(ptn.contract_two_ttns(ttn1,ttn1.conjugate()))\n",
    "        ttn1.tensors[f\"site{i}\"] = a\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ptn.crandn((5,2))\n",
    "b = ptn.crandn((5,2))\n",
    "b = normalize_tensor(b)\n",
    "indices = tuple(range(b.ndim))\n",
    "prod = np.tensordot(b.conj(),a , axes = (indices,indices) )\n",
    "a = a - b * prod\n",
    "a = a / np.sqrt(np.tensordot(a,a.conj(), axes = (indices , indices) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(a,a.conj() , axes = (indices,indices) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(b,b.conj() , axes = (indices,indices) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(a,b.conj() , axes = (indices,indices) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "np.tensordot(mps1.tensors[f\"site{i}\"],mps2.tensors[f\"site{i}\"],axes=((0,1,2),(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "ptn.canonical_form2(mps1)\n",
    "mps1 = normalize(mps1)\n",
    "mps2 = ptn.MatrixProductState.from_tensor_list(tensors2,root_site=5,node_prefix=\"site\")\n",
    "ptn.canonical_form2(mps2)\n",
    "mps2 = normalize(mps2)\n",
    "orthogonalize_against(mps2 , mps1)\n",
    "ptn.contract_two_ttns(mps2, mps1.conjugate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(mps1.tensors[\"site1\"], mps2.tensors[\"site1\"] ,axes = ((0,1,2),(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tensordot(mps1.tensors[\"site2\"],mps2.tensors[\"site2\"].conj(),axes = ((0,1,2),(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [(5, 2), (5, 7, 2), (7, 3, 2), (3, 6, 2), (6, 30, 2), (30, 2)]\n",
    "tensors1 = [ptn.crandn(shape) for shape in shapes]\n",
    "tensors2 = [ptn.crandn(shape) for shape in shapes]\n",
    "tensors3 = [ptn.crandn(shape) for shape in shapes]\n",
    "tensors4 = [ptn.crandn(shape) for shape in shapes]\n",
    "\n",
    "mps1 = ptn.MatrixProductState.from_tensor_list(tensors1,root_site=5,node_prefix=\"site\")\n",
    "tp = ptn.random_tensor_product(mps1, num_operators= len(mps1))\n",
    "tensor = ptn.crandn([2,2,2,2,2,2,\n",
    "                     2,2,2,2,2,2])\n",
    "leg_dict = {\"site0\": 0, \"site1\": 1, \"site2\": 2, \"site3\": 3, \"site4\": 4, \"site5\": 5}\n",
    "hamiltonian = ptn.TTNO.from_tensor(mps1, tensor, leg_dict)\n",
    "\n",
    "results = Krylov_space(mps1,hamiltonian,2)\n",
    "\n",
    "# ptn.canonical_form2(mps1)\n",
    "mps1 = normalize(mps1)\n",
    "\n",
    "mps2 = results[1]\n",
    "# ptn.canonical_form2(mps2)\n",
    "mps2 = normalize(mps2)\n",
    "# orthogonalize_against(mps2 , mps1)\n",
    "\n",
    "mps3 = results[2]\n",
    "# ptn.canonical_form2(mps3)\n",
    "mps3 = normalize(mps3)\n",
    "# orthogonalize_against(mps3 , mps1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mps1.nodes[\"site5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptn.contract_two_ttns(mps1, mps1.conjugate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U , S , B = ptn.truncated_tensor_svd(mps1.tensors[\"site4\"], (0,2), (1,),\n",
    "                                     max_bond_dim=np.inf , rel_tol=-np.inf, total_tol=-np.inf)\n",
    "print(U.shape , S.shape , B.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_dagger = B.conj().T\n",
    "B_dagger_B = B_dagger @ B \n",
    "P = np.eye(B_dagger_B.shape[0]) - B_dagger_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_2 = reduced_density_matrix(mps2,\"site4\")\n",
    "pho_3 = reduced_density_matrix(mps3,\"site4\")\n",
    "pho_4 = reduced_density_matrix(mps4,\"site4\")\n",
    "pho = pho_2 + pho_3 + pho_4\n",
    "\n",
    "pho_baar = P @ pho @ P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[13, 5],\n",
    "              [5, 7]])\n",
    "\n",
    "w, v = np.linalg.eig(A)\n",
    "B_bar = np.conjugate(v.T)\n",
    "S = np.diag(np.sqrt(w))  \n",
    "\n",
    "# Reconstruct A from B and S\n",
    "np.allclose( A , np.dot(np.conjugate(B_bar.T), np.dot(S@S, B_bar)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
