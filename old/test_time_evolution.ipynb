{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pytreenet as ptn\n",
    "from copy import deepcopy\n",
    "from scipy.linalg import expm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               __________ 1 _________         \n",
    "#              |           |          |              \n",
    "#              2      _____6______    4  \n",
    "#              |     |            |   |               \n",
    "#              3     8            7   5            \n",
    "node1, tensor1 = ptn.random_tensor_node((5, 6, 3, 2), identifier=\"site1\")\n",
    "node2, tensor2 = ptn.random_tensor_node((5, 4, 2), identifier=\"site2\")\n",
    "node3, tensor3 = ptn.random_tensor_node((4, 2), identifier=\"site3\")\n",
    "node4, tensor4 = ptn.random_tensor_node((6, 3, 2), identifier=\"site4\")\n",
    "node5, tensor5 = ptn.random_tensor_node((3, 2), identifier=\"site5\")\n",
    "node6, tensor6 = ptn.random_tensor_node((3, 5, 4, 2), identifier=\"site6\")\n",
    "node7, tensor7 = ptn.random_tensor_node((5, 2), identifier=\"site7\")\n",
    "node8, tensor8 = ptn.random_tensor_node((4, 2), identifier=\"site8\")\n",
    "\n",
    "ttn = ptn.TreeTensorNetworkState()\n",
    "\n",
    "ttn.add_root(node1, tensor1)\n",
    "ttn.add_child_to_parent(node2, tensor2, 0, \"site1\", 0)\n",
    "ttn.add_child_to_parent(node3, tensor3, 0, \"site2\", 1)\n",
    "ttn.add_child_to_parent(node4, tensor4, 0, \"site1\", 1)\n",
    "ttn.add_child_to_parent(node5, tensor5, 0, \"site4\", 1)\n",
    "ttn.add_child_to_parent(node6, tensor6, 0, \"site1\", 2)\n",
    "ttn.add_child_to_parent(node7, tensor7, 0, \"site6\", 1)\n",
    "ttn.add_child_to_parent(node8, tensor8, 0, \"site6\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 2), (3,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthogonality_center_id = \"site1\"\n",
    "u_legs = tuple(range(ttn.nodes[orthogonality_center_id].nchildren()))\n",
    "v_legs = (ttn.tensors[orthogonality_center_id].ndim-1,)\n",
    "u_legs , v_legs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2, 2) ['site1', 'site2']\n",
      "(2, 2, 2, 2) ['site1', 'site4']\n"
     ]
    }
   ],
   "source": [
    "X, _, Z = ptn.pauli_matrices()\n",
    "\n",
    "#      ttn.nearest_neighbours() = [('site1', 'site2'),\n",
    "#                                  ('site1', 'site4'),\n",
    "#                                  ('site1', 'site6'),\n",
    "#                                  ('site2', 'site3'),\n",
    "#                                  ('site4', 'site5'),\n",
    "#                                  ('site6', 'site7'),\n",
    "#                                  ('site6', 'site8')]\n",
    "swaplist = ptn.SWAPlist(ttn.nearest_neighbours())\n",
    "\n",
    "swap_op_list = swaplist.into_operators(ttn)\n",
    "# operator_list[n].operator == ptn.swap_gate(2).reshape((2,2,2,2))\n",
    "print(swap_op_list[0].operator.shape ,  swap_op_list[0].node_identifiers)\n",
    "print(swap_op_list[1].operator.shape ,  swap_op_list[1].node_identifiers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_products = []\n",
    "for pairs in ttn.nearest_neighbours():\n",
    "    term = ptn.TensorProduct({pairs[0]: Z, pairs[1]: Z})\n",
    "    tensor_products.append(term)\n",
    "\n",
    "# tensor_products = [ {\"site1\" : Z , \"site2\" : Z},\n",
    "#                     {\"site1\" : Z , \"site4\" : Z},\n",
    "#                     {\"site1\" : Z , \"site6\" : Z},\n",
    "#                     {\"site2\" : Z , \"site3\" : Z},\n",
    "#                     {\"site4\" : Z , \"site5\" : Z},\n",
    "#                     {\"site6\" : Z , \"site7\" : Z},\n",
    "#                     {\"site6\" : Z , \"site8\" : Z}]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitting_int = [3, 0, 1, 4, 2, 5, 6]\n",
    "splitting_tuple = [(3, 1), (0, 1), (1, 1), (4, 1), (2, 1), (5, 1), (6, 1)]\n",
    "\n",
    "swaps_before = [ptn.SWAPlist([]) for i in splitting_tuple]\n",
    "swaps_before[0].extend([(\"site3\", \"site2\"), (\"site2\", \"site1\")])\n",
    "\n",
    "swaps_after = [ptn.SWAPlist([]) for i in range(len(splitting_tuple))]\n",
    "swaps_after[0].extend([(\"site8\", \"site6\"), (\"site6\", \"site7\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trotter = ptn.TrotterSplitting(tensor_products,\n",
    "                     splitting_tuple,\n",
    "                     swaps_before,\n",
    "                     swaps_after)\n",
    "unitary_operators = trotter.exponentiate_splitting(delta_time=0.1 , ttn=ttn)\n",
    "len(unitary_operators) # 2 + 1 + 2 + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site2', 'site1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitary_operators[1].node_identifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ True,  True],\n",
       "         [ True,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True]]],\n",
       "\n",
       "\n",
       "       [[[ True,  True],\n",
       "         [ True,  True]],\n",
       "\n",
       "        [[ True,  True],\n",
       "         [ True,  True]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unitary_operators[1].operator == ptn.swap_gate(2).reshape((2,2,2,2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_time = 0.1\n",
    "unitary_operators = [] \n",
    "i=0\n",
    "split = (3,1)\n",
    "tensor_product = tensor_products[split[0]]\n",
    "# tensor_product = {\"site2\" : Z , \"site3\" : Z}\n",
    "factor = -1j * split[1] * delta_time\n",
    "exponentiated_operator = tensor_product.exp(factor)\n",
    "# exponentiated_operator.operator = exp(factor*Z(site2)*Z(site3)) \n",
    "# exponentiated_operator.node_identifiers = ['site2', 'site3']\n",
    "\n",
    "swaps_before = swaps_before[0].into_operators(ttn)\n",
    "# swaps_before [ swap(1,2) with node_identifiers = ['site1', 'site2']\n",
    "#               swap(2,3) with node_identifiers = ['site2', 'site3']]\n",
    "swaps_after = swaps_after[0].into_operators(ttn)\n",
    "# swaps_after [ swap(3,2) with node_identifiers = ['site3', 'site2']\n",
    "#               swap(2,1) with node_identifiers = ['site2', 'site1']]\n",
    "\n",
    "#            unitary_operators.extend(swaps_before)\n",
    "#            unitary_operators.append(exponentiated_operator)\n",
    "#            unitary_operators.extend(swaps_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m unitary_operators \u001b[38;5;241m=\u001b[39m trotter\u001b[38;5;241m.\u001b[39mexponentiate_splitting(delta_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m , ttn\u001b[38;5;241m=\u001b[39mttn)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mlen\u001b[39m(unitary_operators) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m7\u001b[39m\n\u001b[1;32m---> 20\u001b[0m unitary_operators[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39moperator \u001b[38;5;241m==\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mexpm(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mkron(Z, Z))\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     21\u001b[0m unitary_operators[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnode_identifiers \u001b[38;5;241m==\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msite3\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order : kron(tensor_products[\"site2\"], tensor_products[\"site2\"]) \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "tensor_products = []\n",
    "for pairs in ttn.nearest_neighbours():\n",
    "    term = ptn.TensorProduct({pairs[0]: Z, pairs[1]: Z})\n",
    "    tensor_products.append(term)\n",
    "\n",
    "# tensor_products = [ {\"site1\" : Z , \"site2\" : Z},\n",
    "#                     {\"site1\" : Z , \"site4\" : Z},\n",
    "#                     {\"site1\" : Z , \"site6\" : Z},\n",
    "#                     {\"site2\" : Z , \"site3\" : Z},\n",
    "#                     {\"site4\" : Z , \"site5\" : Z},\n",
    "#                     {\"site6\" : Z , \"site7\" : Z},\n",
    "#                     {\"site6\" : Z , \"site8\" : Z}]\n",
    "\n",
    "splitting = [(3,2), 0, (1,4), 4, 2, 5, 6]\n",
    "\n",
    "trotter = ptn.TrotterSplitting(tensor_products, splitting)\n",
    "# if splitting = None ---> splitting = [0,1,2,3,4,5,6]\n",
    "unitary_operators = trotter.exponentiate_splitting(delta_time=0.1 , ttn=ttn)\n",
    "len(unitary_operators) == 7\n",
    "unitary_operators[0].operator == scipy.linalg.expm(-1j * 2 * 0.1 * np.kron(Z, Z)).reshape((2,2,2,2))\n",
    "unitary_operators[0].node_identifiers == ['site2', 'site3']\n",
    "# order : kron(tensor_products[\"site2\"], tensor_products[\"site2\"]) \n",
    "unitary_operators[1].operator == scipy.linalg.expm(-1j * 1 * 0.1 * np.kron(Z, Z)).reshape((2,2,2,2))\n",
    "unitary_operators[1].node_identifiers == ['site1', 'site2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEBD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ._intital_state          \\ .state (deep copy of initial state) \n",
    "# .trotter_splitting       \\ ._num_time_steps\n",
    "# ._time_step_size         \\ \n",
    "# ._final_time             \\ ._exponents = trotter_splitting.exponentiate_splitting \n",
    "# .operator (not implanted)                (time_step_size,state)\n",
    "         \n",
    "                                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEBD = ptn.TEBD(initial_state = ttn,\n",
    "                trotter_splitting = trotter,\n",
    "                time_step_size= 0.1,\n",
    "                final_time= 10,\n",
    "                operators =[ptn.random_tensor_product(ttn,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 5, 4, 2), (5, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEBD.state.tensors[\"site6\"].shape , TEBD.state.tensors[\"site7\"].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:00<00:00, 143.61it/s]\n"
     ]
    }
   ],
   "source": [
    "TEBD.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 2, 2, 2), (2, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEBD.state.tensors[\"site6\"].shape , TEBD.state.tensors[\"site7\"].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.90945789e+05 -633890.521626j  ,\n",
       "         5.15031734e+05 -546425.63620398j,\n",
       "         6.00892177e+05 -449511.49358909j,\n",
       "         6.52349909e+05 -334385.3866706j ,\n",
       "         6.90042452e+05 -188779.82099765j,\n",
       "         7.42673396e+05   -3300.2891706j ,\n",
       "         8.35316155e+05 +222890.63241016j,\n",
       "         9.78922535e+05 +479164.25608288j,\n",
       "         1.16477013e+06 +744412.34298755j,\n",
       "         1.36585711e+06 +991693.30766453j,\n",
       "         1.54482295e+06+1195023.75148757j,\n",
       "         1.66568855e+06+1336047.29554919j,\n",
       "         1.70536673e+06+1408347.09381241j,\n",
       "         1.66096442e+06+1417979.25792451j,\n",
       "         1.55035604e+06+1380108.95217163j,\n",
       "         1.40584523e+06+1312974.03440492j,\n",
       "         1.26313282e+06+1231314.36769898j,\n",
       "         1.14943477e+06+1141570.09382716j,\n",
       "         1.07487734e+06+1040512.40275589j,\n",
       "         1.03013944e+06 +917750.0071579j ,\n",
       "         9.91118659e+05 +761180.77951685j,\n",
       "         9.28934907e+05 +563411.51424344j,\n",
       "         8.21713817e+05 +326815.81346257j,\n",
       "         6.63966175e+05  +65364.55198509j,\n",
       "         4.70217527e+05 -197516.54376712j,\n",
       "         2.71551790e+05 -434422.94928001j,\n",
       "         1.06211801e+05 -620976.01345368j,\n",
       "         7.48211007e+03 -742011.71349402j,\n",
       "        -6.96258299e+03 -794884.3695196j ,\n",
       "         5.94386226e+04 -788810.71146816j,\n",
       "         1.83672479e+05 -740546.43000603j,\n",
       "         3.31183500e+05 -667949.52082594j,\n",
       "         4.67592644e+05 -583702.19010477j,\n",
       "         5.70023154e+05 -491386.02618417j,\n",
       "         6.34104371e+05 -385261.34297842j,\n",
       "         6.74246264e+05 -253786.69421137j,\n",
       "         7.17138696e+05  -85588.71349353j,\n",
       "         7.90804803e+05 +124280.42182042j,\n",
       "         9.13097171e+05 +370074.88775436j,\n",
       "         1.08372376e+06 +634668.69221254j,\n",
       "         1.28265845e+06 +892797.94601386j,\n",
       "         1.47555886e+06+1117208.55624415j,\n",
       "         1.62436176e+06+1285668.52761517j,\n",
       "         1.69941066e+06+1386495.27271729j,\n",
       "         1.68892567e+06+1420756.34315454j,\n",
       "         1.60254300e+06+1400449.76579465j,\n",
       "         1.46771060e+06+1343357.32188287j,\n",
       "         1.32020855e+06+1266406.75806856j,\n",
       "         1.19210143e+06+1179878.68731323j,\n",
       "         1.10131304e+06+1084477.08188052j,\n",
       "         1.04643471e+06 +972260.33533732j,\n",
       "         1.00853792e+06 +831060.72435334j,\n",
       "         9.59305409e+05 +650782.83500787j,\n",
       "         8.72579975e+05 +429299.08915686j,\n",
       "         7.35230343e+05 +175788.45300514j,\n",
       "         5.53469607e+05  -89751.45284496j,\n",
       "         3.52349939e+05 -340756.78935761j,\n",
       "         1.68543706e+05 -550737.95118881j,\n",
       "         3.88716712e+04 -700093.54503659j,\n",
       "        -1.14676900e+04 -780814.83480829j,\n",
       "         2.31005744e+04 -797522.68564069j,\n",
       "         1.27059202e+05 -764544.96745804j,\n",
       "         2.69356547e+05 -700107.52668064j,\n",
       "         4.14043951e+05 -619700.03539473j,\n",
       "         5.32285080e+05 -530944.87566944j,\n",
       "         6.11563889e+05 -431750.34772188j,\n",
       "         6.58909112e+05 -312360.81107514j,\n",
       "         6.97054623e+05 -160534.98310232j,\n",
       "         7.54932152e+05  +32027.11287638j,\n",
       "         8.55879941e+05 +264339.41007397j,\n",
       "         1.00775357e+06 +523831.82894615j,\n",
       "         1.19846272e+06 +788007.16829296j,\n",
       "         1.39856162e+06+1029583.06092066j,\n",
       "         1.57005323e+06+1223431.07759562j,\n",
       "         1.67839084e+06+1352992.26205161j,\n",
       "         1.70353520e+06+1414022.15344058j,\n",
       "         1.64624494e+06+1414438.36046428j,\n",
       "         1.52743109e+06+1370389.12172631j,\n",
       "         1.38081653e+06+1299962.68572211j,\n",
       "         1.24146580e+06+1216760.9015512j ,\n",
       "         1.13418004e+06+1125586.24221619j,\n",
       "         1.06578515e+06+1021731.42412889j,\n",
       "         1.02396931e+06 +894081.21750429j,\n",
       "         9.83027206e+05 +730884.79326391j,\n",
       "         9.14446789e+05 +526106.83210402j,\n",
       "         7.98576200e+05 +284049.22144818j,\n",
       "         6.33227301e+05  +20528.6477916j ,\n",
       "         4.36140970e+05 -239908.14015754j,\n",
       "         2.40385182e+05 -469867.86339762j,\n",
       "         8.42298516e+04 -646145.04842008j,\n",
       "        -1.02143429e+03 -755550.93044086j,\n",
       "        -1.03991505e+03 -797591.51467762j,\n",
       "         7.71389163e+04 -783136.18109065j,\n",
       "         2.07853753e+05 -729601.88546889j,\n",
       "         3.55715976e+05 -654375.87078369j,\n",
       "         4.87562328e+05 -568794.18110856j,\n",
       "         5.83302690e+05 -474777.36828138j,\n",
       "         6.41902885e+05 -365274.88656611j,\n",
       "         6.80453839e+05 -228318.47203464j,\n",
       "         7.26703761e+05  -53205.13957145j,\n",
       "         8.07721779e+05 +163429.92016589j],\n",
       "       [ 0.00000000e+00      +0.j        ,\n",
       "         1.00000000e-01      +0.j        ,\n",
       "         2.00000000e-01      +0.j        ,\n",
       "         3.00000000e-01      +0.j        ,\n",
       "         4.00000000e-01      +0.j        ,\n",
       "         5.00000000e-01      +0.j        ,\n",
       "         6.00000000e-01      +0.j        ,\n",
       "         7.00000000e-01      +0.j        ,\n",
       "         8.00000000e-01      +0.j        ,\n",
       "         9.00000000e-01      +0.j        ,\n",
       "         1.00000000e+00      +0.j        ,\n",
       "         1.10000000e+00      +0.j        ,\n",
       "         1.20000000e+00      +0.j        ,\n",
       "         1.30000000e+00      +0.j        ,\n",
       "         1.40000000e+00      +0.j        ,\n",
       "         1.50000000e+00      +0.j        ,\n",
       "         1.60000000e+00      +0.j        ,\n",
       "         1.70000000e+00      +0.j        ,\n",
       "         1.80000000e+00      +0.j        ,\n",
       "         1.90000000e+00      +0.j        ,\n",
       "         2.00000000e+00      +0.j        ,\n",
       "         2.10000000e+00      +0.j        ,\n",
       "         2.20000000e+00      +0.j        ,\n",
       "         2.30000000e+00      +0.j        ,\n",
       "         2.40000000e+00      +0.j        ,\n",
       "         2.50000000e+00      +0.j        ,\n",
       "         2.60000000e+00      +0.j        ,\n",
       "         2.70000000e+00      +0.j        ,\n",
       "         2.80000000e+00      +0.j        ,\n",
       "         2.90000000e+00      +0.j        ,\n",
       "         3.00000000e+00      +0.j        ,\n",
       "         3.10000000e+00      +0.j        ,\n",
       "         3.20000000e+00      +0.j        ,\n",
       "         3.30000000e+00      +0.j        ,\n",
       "         3.40000000e+00      +0.j        ,\n",
       "         3.50000000e+00      +0.j        ,\n",
       "         3.60000000e+00      +0.j        ,\n",
       "         3.70000000e+00      +0.j        ,\n",
       "         3.80000000e+00      +0.j        ,\n",
       "         3.90000000e+00      +0.j        ,\n",
       "         4.00000000e+00      +0.j        ,\n",
       "         4.10000000e+00      +0.j        ,\n",
       "         4.20000000e+00      +0.j        ,\n",
       "         4.30000000e+00      +0.j        ,\n",
       "         4.40000000e+00      +0.j        ,\n",
       "         4.50000000e+00      +0.j        ,\n",
       "         4.60000000e+00      +0.j        ,\n",
       "         4.70000000e+00      +0.j        ,\n",
       "         4.80000000e+00      +0.j        ,\n",
       "         4.90000000e+00      +0.j        ,\n",
       "         5.00000000e+00      +0.j        ,\n",
       "         5.10000000e+00      +0.j        ,\n",
       "         5.20000000e+00      +0.j        ,\n",
       "         5.30000000e+00      +0.j        ,\n",
       "         5.40000000e+00      +0.j        ,\n",
       "         5.50000000e+00      +0.j        ,\n",
       "         5.60000000e+00      +0.j        ,\n",
       "         5.70000000e+00      +0.j        ,\n",
       "         5.80000000e+00      +0.j        ,\n",
       "         5.90000000e+00      +0.j        ,\n",
       "         6.00000000e+00      +0.j        ,\n",
       "         6.10000000e+00      +0.j        ,\n",
       "         6.20000000e+00      +0.j        ,\n",
       "         6.30000000e+00      +0.j        ,\n",
       "         6.40000000e+00      +0.j        ,\n",
       "         6.50000000e+00      +0.j        ,\n",
       "         6.60000000e+00      +0.j        ,\n",
       "         6.70000000e+00      +0.j        ,\n",
       "         6.80000000e+00      +0.j        ,\n",
       "         6.90000000e+00      +0.j        ,\n",
       "         7.00000000e+00      +0.j        ,\n",
       "         7.10000000e+00      +0.j        ,\n",
       "         7.20000000e+00      +0.j        ,\n",
       "         7.30000000e+00      +0.j        ,\n",
       "         7.40000000e+00      +0.j        ,\n",
       "         7.50000000e+00      +0.j        ,\n",
       "         7.60000000e+00      +0.j        ,\n",
       "         7.70000000e+00      +0.j        ,\n",
       "         7.80000000e+00      +0.j        ,\n",
       "         7.90000000e+00      +0.j        ,\n",
       "         8.00000000e+00      +0.j        ,\n",
       "         8.10000000e+00      +0.j        ,\n",
       "         8.20000000e+00      +0.j        ,\n",
       "         8.30000000e+00      +0.j        ,\n",
       "         8.40000000e+00      +0.j        ,\n",
       "         8.50000000e+00      +0.j        ,\n",
       "         8.60000000e+00      +0.j        ,\n",
       "         8.70000000e+00      +0.j        ,\n",
       "         8.80000000e+00      +0.j        ,\n",
       "         8.90000000e+00      +0.j        ,\n",
       "         9.00000000e+00      +0.j        ,\n",
       "         9.10000000e+00      +0.j        ,\n",
       "         9.20000000e+00      +0.j        ,\n",
       "         9.30000000e+00      +0.j        ,\n",
       "         9.40000000e+00      +0.j        ,\n",
       "         9.50000000e+00      +0.j        ,\n",
       "         9.60000000e+00      +0.j        ,\n",
       "         9.70000000e+00      +0.j        ,\n",
       "         9.80000000e+00      +0.j        ,\n",
       "         9.90000000e+00      +0.j        ,\n",
       "         1.00000000e+01      +0.j        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEBD.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tdvp_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#               __________ 1 _________         \n",
    "#              |           |          |              \n",
    "#              2           5          3      \n",
    "#                                     |          \n",
    "#                                     4  \n",
    "\n",
    "ttn = ptn.TreeTensorNetwork()\n",
    "node1, tensor1 = ptn.random_tensor_node((2, 2, 2, 2), identifier=\"id1\")\n",
    "node2, tensor2 = ptn.random_tensor_node((2, 2), identifier=\"id2\")\n",
    "node3, tensor3 = ptn.random_tensor_node((2, 2, 5), identifier=\"id3\")\n",
    "node4, tensor4 = ptn.random_tensor_node((2, 2), identifier=\"id4\")\n",
    "node5, tensor5 = ptn.random_tensor_node((2, 2), identifier=\"id5\")\n",
    "ttn.add_root(node1, tensor1)\n",
    "ttn.add_child_to_parent(node2, tensor2, 0, \"id1\", 0)\n",
    "ttn.add_child_to_parent(node3, tensor3, 0, \"id1\", 1)\n",
    "ttn.add_child_to_parent(node4, tensor4, 0, \"id3\", 1)\n",
    "ttn.add_child_to_parent(node5, tensor5, 0, \"id1\", 2)\n",
    "\n",
    "tensor = ptn.crandn([2,2,5,2,2,\n",
    "                     2,2,5,2,2])\n",
    "leg_dict = {\"id1\": 0, \"id2\": 1, \"id3\": 2, \"id4\": 3, \"id5\": 4}\n",
    "ttno = ptn.TTNO.from_tensor(ttn, tensor, leg_dict)\n",
    "\n",
    "tp = ptn.TensorProduct({\"id1\": \"1\",\n",
    "                        \"id2\": \"2\",\n",
    "                        \"id3\": \"3\",\n",
    "                        \"id4\": \"4\",\n",
    "                        \"id5\": \"5\"})\n",
    "conversion_dictionary = {\"1\": ptn.crandn((2, 2)),\n",
    "                         \"2\": ptn.crandn((2, 2)),\n",
    "                         \"3\": ptn.crandn((5, 5)),\n",
    "                         \"4\": ptn.crandn((2, 2)),\n",
    "                         \"5\": ptn.crandn((2, 2))}\n",
    "H = ptn.Hamiltonian( tp , conversion_dictionary)\n",
    "ttno = ptn.TTNO.from_hamiltonian( H, ttn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pytreenet' has no attribute 'CachedSiteTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m CST_id3 \u001b[38;5;241m=\u001b[39m \u001b[43mptn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCachedSiteTensor\u001b[49m(ttn\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid3\u001b[39m\u001b[38;5;124m\"\u001b[39m] , ttno\u001b[38;5;241m.\u001b[39mnodes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid3\u001b[39m\u001b[38;5;124m\"\u001b[39m] ,\n\u001b[0;32m      2\u001b[0m                               ttn\u001b[38;5;241m.\u001b[39mtensors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid3\u001b[39m\u001b[38;5;124m\"\u001b[39m], ttno\u001b[38;5;241m.\u001b[39mtensors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid3\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# tensor = CachedSiteTensor.compute()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m CST_id3\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pytreenet' has no attribute 'CachedSiteTensor'"
     ]
    }
   ],
   "source": [
    "CST_id3 = ptn.CachedSiteTensor(ttn.nodes[\"id3\"] , ttno.nodes[\"id3\"] ,\n",
    "                              ttn.tensors[\"id3\"], ttno.tensors[\"id3\"])\n",
    "# tensor = CachedSiteTensor.compute()\n",
    "CST_id3.compute().shape\n",
    "# only works when all nodes have one open leg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PartialTreeCach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                |2\n",
    "                |\n",
    "                r\n",
    "               / \\\\\n",
    "         3|  5/  6\\\\   |4\n",
    "          |  /     \\\\  |\n",
    "           c1        c2\n",
    "\"\"\"\n",
    "state = ptn.random_small_ttns()\n",
    "tensor_prod = [ptn.TensorProduct({\"c1\": \"I3\", \"root\": \"root_op1\", \"c2\": \"I4\"}),\n",
    "               ptn.TensorProduct({\"c1\": \"c1_op\", \"root\": \"root_op1\", \"c2\": \"I4\"}),\n",
    "               ptn.TensorProduct({\"c1\": \"c1_op\", \"root\": \"root_op2\", \"c2\": \"c2_op\"}),\n",
    "               ptn.TensorProduct({\"c1\": \"c1_op\", \"root\": \"I2\", \"c2\": \"c2_op\"})]\n",
    "conversion_dict = {\"root_op1\": ptn.random_hermitian_matrix(),\n",
    "                   \"root_op2\": ptn.random_hermitian_matrix(),\n",
    "                   \"I2\": np.eye(2),\n",
    "                   \"c1_op\": ptn.random_hermitian_matrix(size=3),\n",
    "                   \"I3\": np.eye(3),\n",
    "                   \"c2_op\": ptn.random_hermitian_matrix(size=4),\n",
    "                   \"I4\": np.eye(4)}\n",
    "ham = ptn.Hamiltonian(tensor_prod, conversion_dict)\n",
    "hamiltonian = ptn.TTNO.from_hamiltonian(ham, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_tree_cache = ptn.PartialTreeCachDict()\n",
    "\n",
    "# tdvp._initialize_partial_tree_cache():\n",
    "\n",
    "# tdvp.update_tree_cache(node_ide,next_node_ide):\n",
    "node_id = \"c1\"\n",
    "next_node_id = \"root\"\n",
    "tensor = ptn.contract_any(node_id, next_node_id,\n",
    "                         state, hamiltonian,\n",
    "                         partial_tree_cache)\n",
    "partial_tree_cache.add_entry(node_id, next_node_id, tensor)\n",
    "\n",
    "# tdvp.update_tree_cache(node_ide,next_node_ide):\n",
    "node_id = \"root\"\n",
    "next_node_id = \"c2\"\n",
    "tensor = ptn.contract_any(node_id, next_node_id,\n",
    "                         state, hamiltonian,\n",
    "                         partial_tree_cache)\n",
    "partial_tree_cache.add_entry(node_id, next_node_id, tensor)\n",
    "\n",
    "np.allclose(partial_tree_cache.get_entry(\"root\", \"c2\"), tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDVPUpdatePathFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                0\\n               / \\\\\\n              /   \\\\\\n             1     6\\n            / \\\\    \\\\\\n           /   \\\\    \\\\\\n          2     3     7\\n               / \\\\\\n              /   \\\\\\n             4     5\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "\"\"\"\n",
    "                0\n",
    "               / \\\\\n",
    "              /   \\\\\n",
    "             1     6\n",
    "            / \\\\    \\\\\n",
    "           /   \\\\    \\\\\n",
    "          2     3     7\n",
    "               / \\\\\n",
    "              /   \\\\\n",
    "             4     5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site4 ['site4', 'site3', 'site1', 'site0']\n",
      "['site4']\n",
      "['site5', 'site3']\n",
      "['site2', 'site1']\n",
      "['site7', 'site6', 'site0']\n",
      "site5\n",
      "site7\n",
      "['site0', 'site1', 'site3', 'site4']\n",
      "['site0', 'site6', 'site7']\n",
      "['site4', 'site5', 'site3', 'site2', 'site1', 'site0', 'site6', 'site7']\n"
     ]
    }
   ],
   "source": [
    "PF = ptn.TDVPUpdatePathFinder(ttn)\n",
    "print( PF.start , PF.main_path)\n",
    "print( PF.path_for_branch(\"site4\"))\n",
    "print( PF.path_for_branch(\"site3\"))\n",
    "print( PF.path_for_branch(\"site1\"))\n",
    "print( PF.path_for_branch(\"site0\"))\n",
    "print( PF.find_furthest_non_visited_leaf(['site4', 'site3', 'site1', 'site0']))\n",
    "print( PF.find_furthest_non_visited_leaf([\"site4\",\"site5\",\"site3\",\"site2\",\"site1\"]))\n",
    "print( PF.find_main_path_down_from_root([\"site7\",\"site6\",\"site3\"]))\n",
    "print( PF.path_down_from_root([\"site4\",\"site5\",\"site3\",\"site2\",\"site1\"]))\n",
    "print( PF.find_path())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeEvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[-3716.88236212-664.0096184j    462.31847607 +32.62464157j]\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "tp1 = ptn.random_tensor_product(ttn, 3)\n",
    "tp2 = ptn.random_tensor_product(ttn, 4)\n",
    "\n",
    "TE = ptn.TTNTimeEvolution(initial_state = ttn,\n",
    "                       time_step_size= 0.1,\n",
    "                       final_time= 10,\n",
    "                       operators = [tp1, tp2])\n",
    "print(TE.num_time_steps)  \n",
    "# TE.results --> Currently there are no results\n",
    "print(TE.evaluate_operators())\n",
    "print(TE._operator_index_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "TE = ptn.TimeEvolution(initial_state = ttn,\n",
    "                       time_step_size= 0.1,\n",
    "                       final_time= 10,\n",
    "                       operators = [tp1, tp2])\n",
    "print(TE._operator_index_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2, 2, 2, 2, 2, 2) (256, 256)\n"
     ]
    }
   ],
   "source": [
    "ttn = ptn.random_big_ttns_two_root_children()\n",
    "tp = ptn.random_tensor_product(ttn, len(ttn.nodes))\n",
    "\n",
    "psi, contraction_order = ttn.completely_contract_tree(to_copy=True)\n",
    "op = tp.into_operator(order = contraction_order)\n",
    "hamiltonian = op.operator\n",
    "\n",
    "print( psi.shape , hamiltonian.shape)\n",
    "\n",
    "# e^(-i*H*delta_time) |psi> (forward)\n",
    "psi_time_evolved = ptn.time_evolve(psi = psi,\n",
    "                                   hamiltonian = hamiltonian,\n",
    "                                   time_difference = 0.1,\n",
    "                                   forward = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDVPAlgorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .initial_state , .hamiltonian , .time_step_size , .final_time , .operators\n",
    "# TDVP.update_path == PF.find_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                0\n",
    "               / \\\\\n",
    "              /   \\\\\n",
    "             1     6\n",
    "            / \\\\    \\\\\n",
    "           /   \\\\    \\\\\n",
    "          2     3     7\n",
    "               / \\\\\n",
    "              /   \\\\\n",
    "             4     5\n",
    "\"\"\"\n",
    "ref_tree = random_big_ttns_two_root_children2()\n",
    "tp1 = ptn.TensorProduct({\"site0\": \"0\",\"site1\": \"1\"})\n",
    "tp2 = ptn.TensorProduct({\"site2\": \"2\",\"site3\": \"3\",\"site4\": \"4\"})\n",
    "tp3 = ptn.TensorProduct({\"site5\": \"5\",\"site6\": \"6\",\"site7\": \"7\"})\n",
    "\n",
    "conversion_dictionary = {\"0\": ptn.random_hermitian_matrix(2),\n",
    "                         \"1\": ptn.random_hermitian_matrix(3),\n",
    "                         \"2\": ptn.random_hermitian_matrix(4),\n",
    "                         \"3\": ptn.random_hermitian_matrix(5),\n",
    "                         \"4\": ptn.random_hermitian_matrix(6),\n",
    "                         \"5\": ptn.random_hermitian_matrix(7),\n",
    "                         \"6\": ptn.random_hermitian_matrix(8),\n",
    "                         \"7\": ptn.random_hermitian_matrix(9),\n",
    "                         \"I2\" : np.eye(2),\"I3\" : np.eye(3),\"I4\" : np.eye(4),\"I5\" : np.eye(5),\n",
    "                         \"I6\" : np.eye(6),\"I7\" : np.eye(7),\"I8\" : np.eye(8),\"I9\" : np.eye(9)}\n",
    "H = ptn.Hamiltonian( [tp1,tp2,tp3] , conversion_dictionary)\n",
    "H = H.pad_with_identities(ref_tree)\n",
    "hamiltonian = ptn.TTNO.from_hamiltonian(H, ref_tree) \n",
    "\n",
    "tdvp = ptn.TDVPAlgorithm(ref_tree, hamiltonian, 0.1 , 1,\n",
    "                        ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}))                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['site7', 'site6', 'site0', 'site2', 'site1', 'site5', 'site3', 'site4'],\n",
       " {'site0': 'site1',\n",
       "  'site1': 'site3',\n",
       "  'site3': 'site4',\n",
       "  'site7': 'site6',\n",
       "  'site6': 'site0',\n",
       "  'site2': 'site1',\n",
       "  'site5': 'site3'})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial partial tree cache is besed on (rev_update_path , next_node_id_dict[rev_update_path])\n",
    "rev_update_path , next_node_id_dict = tdvp._find_caching_path()\n",
    "rev_update_path , next_node_id_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## update_tree_cache ## \n",
    "\n",
    "# (\"site7\", \"site6\")  --> contract_leaf\n",
    "ket_node, ket_tensor = ref_tree[\"site7\"]\n",
    "bra_tensor = ket_tensor.conj()\n",
    "ham_node, ham_tensor = hamiltonian[\"site7\"]\n",
    "# ham_tensor = (2, 9, 9) , bra_tensor = (2, 9)\n",
    "bra_ham = np.tensordot(ham_tensor, bra_tensor,\n",
    "                       axes=(ham_node.nneighbours(),  # 1\n",
    "                             ket_node.nneighbours())) # 1\n",
    "bra_ham_ket = np.tensordot(ket_tensor, bra_ham,\n",
    "                          axes=(ket_node.nneighbours(),  # 1 \n",
    "                                ham_node.nneighbours())) # 1\n",
    "# bra_ham_ket.shape = (2, 2 ,2)\n",
    "\n",
    "# (\"site6\", \"site0\") ---> contract_subtrees_using_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_init_pairs = [(\"site4\",\"site3\"),(\"site3\",\"site5\"),(\"site3\",\"site1\"),\n",
    "                          (\"site1\",\"site2\"),(\"site1\",\"site0\"),(\"site0\",\"site6\"),\n",
    "                          (\"site6\",\"site7\"),(\"site1\",\"site2\")]\n",
    "for pair in non_init_pairs:\n",
    "    tdvp.update_tree_cache(pair[0],pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 18)\n"
     ]
    }
   ],
   "source": [
    "## _contract_all_except_node ##\n",
    "#            (out)\n",
    "#    |n-1     |n      |0           \n",
    "#    |        |       |          \n",
    "#    |--------H-------|            \n",
    "#    |        |       |             \n",
    "#    |2n      |2n+1   |n+1   \n",
    "#            (in)\n",
    "\n",
    "################## \"site7\" #####################\n",
    "target_node , tensor  = hamiltonian[\"site7\"]  # (2, 9, 9)\n",
    "neighbours = target_node.neighbouring_nodes() # ['site6']\n",
    "\n",
    "# for neighbours\n",
    "neighbour_id = 'site6'\n",
    "cached_tensor = tdvp.partial_tree_cache.get_entry('site6','site7')\n",
    "tensor = np.tensordot(tensor, cached_tensor,axes=((0,1)))\n",
    "tensor = tensor.transpose(tdvp._find_tensor_leg_permutation(\"site7\")) # (3, 0, 2, 1)\n",
    "# tensor.shape = (2, 9, 2, 9)\n",
    "\n",
    "#    |1      |0       \n",
    "#    |       |     \n",
    "#    H-------|         \n",
    "#    |       |     \n",
    "#    |3      |2\n",
    "\n",
    "tensor = tdvp._get_effective_site_hamiltonian(\"site7\")\n",
    "# tensor.shape = (18,18)\n",
    "\n",
    "################## \"site6\" ######################\n",
    "target_node , tensor  = hamiltonian[\"site6\"]  # (2, 8, 8)\n",
    "neighbours = target_node.neighbouring_nodes() # ['site0','site7']\n",
    "\n",
    "# for neighbours\n",
    "neighbour_id = 'site0'\n",
    "cached_tensor = tdvp.partial_tree_cache.get_entry('site0','site6')\n",
    "tensor = np.tensordot(tensor, cached_tensor,axes=((0,1)))\n",
    "\n",
    "neighbour_id = 'site7'\n",
    "cached_tensor = tdvp.partial_tree_cache.get_entry('site7','site6')\n",
    "tensor = np.tensordot(tensor, cached_tensor,axes=((0,1)))\n",
    "tensor = tensor.transpose(tdvp._find_tensor_leg_permutation(\"site6\")) # (3, 0, 2, 1)\n",
    "# tensor.shape = (2, 2, 8, 2, 2, 8)\n",
    "\n",
    "#    |1       |2      |0     \n",
    "#    |        |       |     \n",
    "#    |--------H-------|         \n",
    "#    |        |       |     \n",
    "#    |4       |5      |3\n",
    "\n",
    "tensor = tdvp._get_effective_site_hamiltonian(\"site7\")\n",
    "# first tranpose(0,1,2,3,4,5) then reshape (2*8*2,2*8*2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdvp1 = deepcopy(tdvp)\n",
    "# _update_link(\"site1\",\"site3\")\n",
    "tdvp1._split_updated_site(\"site1\",\"site3\")\n",
    "# q_legs = ptn.LegSpecification(\"site0\",[\"site2\"],[3])\n",
    "# r_legs = ptn.LegSpecification(None,[\"site3\"],[])\n",
    "# tdvp1.state.split_node_qr(\"site1\", q_legs, r_legs,\n",
    "#                          q_identifier=\"site1\",\n",
    "#                          r_identifier= tdvp.create_link_id(\"site1\", \"site3\"))\n",
    "# site1 = Q\n",
    "# link_site1_with_site3 = R \n",
    "# update_tree_cache(Q,\"site3\")\n",
    "tdvp1._time_evolve_link_tensor(\"site1\",\"site3\") # include _get_effective_link_hamiltonian\n",
    "ham = tdvp1._get_effective_link_hamiltonian(\"site1\", \"site3\")\n",
    "# e^(i*ham*t) |link_site1_with_site3>  \n",
    "# contract R to site0\n",
    "# orthogonality center = site0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdvp.state.move_orthogonalization_center(\"site4\")\n",
    "tdvp._move_orth_and_update_cache_for_path([\"site4\",\"site3\",\"site1\"])\n",
    "\n",
    "#1    # move orthogonality center to site3\n",
    "      # update partial_tree_cache (site4,site3)\n",
    "#2    # move orthogonality center to site1\n",
    "      # update partial_tree_cache (site3,site1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FirstOrderOneSiteTDVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "                0\n",
    "               / \\\\\n",
    "              /   \\\\\n",
    "             1     6\n",
    "            / \\\\    \\\\\n",
    "           /   \\\\    \\\\\n",
    "          2     3     7\n",
    "               / \\\\\n",
    "              /   \\\\\n",
    "             4     5\n",
    "\"\"\"\n",
    "ref_tree = ptn.random_big_ttns_two_root_children()\n",
    "hamiltonian = ptn.TTNO.from_hamiltonian(ptn.random_hamiltonian_compatible(),ref_tree)\n",
    "\n",
    "tdvp = ptn.TDVPAlgorithm(ref_tree, hamiltonian, 0.1 , 1,\n",
    "                        ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['site4', 'site5', 'site3', 'site2', 'site1', 'site0', 'site6', 'site7'],\n",
       " [['site3', 'site5'],\n",
       "  ['site3'],\n",
       "  ['site1', 'site2'],\n",
       "  ['site1'],\n",
       "  ['site0'],\n",
       "  ['site6'],\n",
       "  ['site7']])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdvp.update_path , tdvp.orthogonalization_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest_distance_neighbour(node , distance_dict: dict[str, int]) -> str:\n",
    "    \"\"\"\n",
    "    Finds identifier of the neighbour of node with the minimal distance in\n",
    "    distance dict, i.e. minimum distance to the orthogonality center.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node : Node\n",
    "        Node for which to search.\n",
    "    distance_dict : dict\n",
    "        Dictionary with the distance of every node to the orthogonality center.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    minimum_distance_neighbour_id : str\n",
    "        Identifier of the neighbour of node with minimum distance to in\n",
    "        distance_dict.\n",
    "\n",
    "    \"\"\"\n",
    "    neighbour_ids = node.neighbouring_nodes()\n",
    "    neighbour_distance_dict = {neighbour_id: distance_dict[neighbour_id]\n",
    "                               for neighbour_id in neighbour_ids}\n",
    "    minimum_distance_neighbour_id = min(neighbour_distance_dict,\n",
    "                                        key=neighbour_distance_dict.get)\n",
    "    return minimum_distance_neighbour_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FO1s = ptn.FirstOrderOneSiteTDVP(ref_tree, hamiltonian, 0.1 , 1,\n",
    "                                 [ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}),\n",
    "                                  ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[1]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site4', 'site5', 'site3', 'site2', 'site1', 'site0', 'site6', 'site7']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inital orthogonality_center_id is update_path[0]\n",
    "FO1s.update_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['site3', 'site5'],\n",
       " ['site3'],\n",
       " ['site1', 'site2'],\n",
       " ['site1'],\n",
       " ['site0'],\n",
       " ['site6'],\n",
       " ['site7']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FO1s.orthogonalization_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_one_time : \n",
    "\n",
    "# FO1s._first_update(\"site4\")\n",
    "# FO1s._normal_update(\"site5\",1)\n",
    "# FO1s._final_update(\"site3\",2)\n",
    "# ....\n",
    "# FO1s._final_update(\"site7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _first_update(\"site4\")\n",
    "\n",
    "# update_site(\"site4\")\n",
    "\n",
    "# next_node_id = orthogonalization_path[0][0] = \"site3\"\n",
    "# update_link(\"site4\",\"site3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_update(\"site5\",i=1)\n",
    "\n",
    "# \n",
    "# _move_orth_and_update_cache_for_path(orthogonalization_path[i-1]= ['site3', 'site5'] )\n",
    "#  update_site(\"site5\")\n",
    "\n",
    "# next_node_id = orthogonalization_path[i][0] = \"site3\"\n",
    "# update_link(\"site5\",\"site3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_update(\"site7\")\n",
    "\n",
    "# _move_orth_and_update_cache_for_path(['site7'])\n",
    "# update_site(\"site7\")\n",
    "\n",
    "# move_orthogonalization_center(\"site4\")\n",
    "# self._init_partial_tree_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SecondOrderOneSiteTDVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SO1s = ptn.SecondOrderOneSiteTDVP(ref_tree, hamiltonian, 0.1 , 1,\n",
    "                                 ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SecondOrderOneSiteTDVP' object has no attribute 'run_one_time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mSO1s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_one_time\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# forward_sweep()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# final_forward_update()\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# backward_sweep()\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SecondOrderOneSiteTDVP' object has no attribute 'run_one_time'"
     ]
    }
   ],
   "source": [
    "# SO1s.run_one_time()\n",
    "\n",
    "# forward_sweep()\n",
    "# final_forward_update()\n",
    "# backward_sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_sweep() :\n",
    "# update with 0.5 factor according to update_path until the last one \n",
    "# last opertation : _update_link(site6, site7)\n",
    "\n",
    "# final_forward_update() :\n",
    "# update last update_path[-1]=\"site7\" with factor 1 \n",
    "# _update_site(site7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site7', 'site6', 'site0', 'site1', 'site2', 'site3', 'site5', 'site4']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO1s.backwards_update_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['site6'],\n",
       " ['site0'],\n",
       " ['site1'],\n",
       " ['site2', 'site1'],\n",
       " ['site3'],\n",
       " ['site5', 'site3'],\n",
       " ['site4']]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO1s.backwards_orth_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward_sweep() :\n",
    "\n",
    "#1 update_first_backward_link() : \n",
    "#     update_link(site7, backwards_update_path[1] = site6 , 0.5)\n",
    "#2 normal_backward_update('site6', 2) : \n",
    "#     update_site(site6 , 0.5)\n",
    "#     move_orth_and_update_cache_for_path( backwards_orth_path[2-1] )\n",
    "#     update_link(site6, backwards_update_path[2+1]=site0 , 0.5)\n",
    "# normal_backward_update('site0', 3)  \n",
    "#      ....\n",
    "# normal_backward_update('site5', 7) \n",
    "\n",
    "# final_backward_update('site4') :\n",
    "#      update_site(site4 , 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FO1s = ptn.FirstOrderOneSiteTDVP(ref_tree, hamiltonian, 0.1 , 1,\n",
    "                                 [ptn.random_tensor_product(ref_tree, 3),\n",
    "                                  ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[1]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1320.5690191446304-744.783921936321j)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <state|tp|state>\n",
    "tp = FO1s.operators[0]\n",
    "FO1s.evaluate_operator(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <state|FO1s.operators|state>\n",
    "FO1s.evaluate_operators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j],\n",
       "       [0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FO1s._init_results(evaluation_time =2) \n",
    "# oprerator 1 exp. value   [_ ,_ ,_ ,_ ,_ ,_]     num_time_steps//evaluation_time + 1 elements\n",
    "# oprerator 2 exp. value   [_ ,_ ,_ ,_ ,_ ,_]\n",
    "# evaluation time          [0 ,.2, .4, .6, ,.8, 1]\n",
    "FO1s.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.+0.j],\n",
       "       [0.+0.j],\n",
       "       [0.+0.j]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FO1s._init_results(evaluation_time=\"inf\")\n",
    "# only evaluates at the final time\n",
    "FO1s.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 72.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan+nanj nan+nanj nan+nanj nan+nanj nan+nanj nan+nanj]\n",
      " [nan+nanj nan+nanj nan+nanj nan+nanj nan+nanj nan+nanj]\n",
      " [0.  +0.j 0.2 +0.j 0.4 +0.j 0.6 +0.j 0.8 +0.j 1.  +0.j]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FO1s.run(evaluation_time = 2 )\n",
    "print(FO1s.results)\n",
    "# FO1s.operator_results(realise = True) = np.real(self.results[0:-1])\n",
    "# FO1s.times() = FO1s.results[-1]\n",
    "FO1s.results_real()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 36.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.90500409e+03+9.09494702e-13j, 4.67107746e+03-9.09494702e-13j,\n",
       "        5.16942669e+03-2.72848411e-12j, 9.08538912e+03+4.54747351e-13j,\n",
       "        1.32292649e+04+4.54747351e-13j, 1.55440002e+04+2.27373675e-12j],\n",
       "       [0.00000000e+00+0.00000000e+00j, 2.00000000e-01+0.00000000e+00j,\n",
       "        4.00000000e-01+0.00000000e+00j, 6.00000000e-01+0.00000000e+00j,\n",
       "        8.00000000e-01+0.00000000e+00j, 1.00000000e+00+0.00000000e+00j]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SO1s = ptn.SecondOrderOneSiteTDVP(ref_tree, hamiltonian, 0.1 , 1,\n",
    "                                 ptn.TensorProduct({\"site0\": ptn.pauli_matrices()[0]}))\n",
    "\n",
    "SO1s.run(evaluation_time = 2 )\n",
    "SO1s.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_tdvp_on_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tensor0 = ptn.random_tensor_node((4,2), \"site_0\")\n",
    "_, tensor1 = ptn.random_tensor_node((4,5,3), \"site_1\")\n",
    "_, tensor2 = ptn.random_tensor_node((5,6,4), \"site_2\")\n",
    "_, tensor3 = ptn.random_tensor_node((6,5), \"site_3\")\n",
    "tensor_list = [tensor0, tensor1, tensor2, tensor3]\n",
    "mps = ptn.MatrixProductState.from_tensor_list(tensor_list,root_site=1,\n",
    "                                             node_prefix=\"site_\")\n",
    "ref_mps = deepcopy(mps)\n",
    "\n",
    "matrix = ptn.random_hermitian_matrix((2*3*4*5))\n",
    "matrix = matrix.reshape(2,3,4,5,2,3,4,5)\n",
    "leg_dict = {\"site_\"+str(i): i for i in range(4)}\n",
    "mpo = ptn.TTNO.from_tensor(mps, matrix, leg_dict)\n",
    "\n",
    "\n",
    "operators = [ptn.bosonic_operators(i)[2] for i in range(2,6)]\n",
    "operators = [ptn.TensorProduct({f\"site_{i}\": op}) for i, op in enumerate(operators)]\n",
    "operators.append(ptn.TensorProduct({f\"site_{i-2}\": np.eye(i) for i in range(2,6)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['site_3', 'site_2', 'site_1', 'site_0'],\n",
       " [['site_2'], ['site_1'], ['site_0']])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdvp = ptn.FirstOrderOneSiteTDVP(ref_mps, mpo, 0.1 , 1,operators)\n",
    "tdvp.update_path , tdvp.orthogonalization_path              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from pytreenet.contractions.state_operator_contraction import (contract_leaf, \n",
    "                                                               contract_subtrees_using_dictionary)\n",
    "\n",
    "ref_mps = deepcopy(tdvp.state) # tdvp.state is in canonical form\n",
    "\n",
    "\n",
    "# initial partial tree cache\n",
    "ref_cache_dict = ptn.PartialTreeCachDict()\n",
    "cache0 = contract_leaf(\"site_0\", ref_mps, mpo)\n",
    "ref_cache_dict.add_entry(\"site_0\", \"site_1\", cache0)\n",
    "cache1 = contract_subtrees_using_dictionary(\"site_1\", \"site_2\",\n",
    "                                                    ref_mps, mpo,\n",
    "                                                    ref_cache_dict)\n",
    "ref_cache_dict.add_entry(\"site_1\", \"site_2\", cache1)\n",
    "cache_2 = contract_subtrees_using_dictionary(\"site_2\", \"site_3\",\n",
    "                                                     ref_mps, mpo,\n",
    "                                                     ref_cache_dict)\n",
    "ref_cache_dict.add_entry(\"site_2\", \"site_3\", cache_2)\n",
    "# ref_cache_dict = tdvp.partial_tree_cache\n",
    "\n",
    "# tdvp._first_update(\"site_3\") : \n",
    "# tdvp.update_site(\"site_3\") :\n",
    "hamiltonian_eff_site = tdvp._get_effective_site_hamiltonian(\"site_3\") # (30,30)\n",
    "hamiltonian_eff_site2 = np.tensordot(mpo.tensors[\"site_3\"],\n",
    "                                     tdvp.partial_tree_cache.get_entry(\"site_2\", \"site_3\"),\n",
    "                                     axes=(mpo.nodes[\"site_3\"].neighbour_index(\"site_2\"),1))\n",
    "hamiltonian_eff_site2 = np.transpose(hamiltonian_eff_site2, (3,0,2,1)).reshape(30,30)\n",
    "print(np.allclose(hamiltonian_eff_site2, hamiltonian_eff_site))\n",
    "\n",
    "psi = tdvp.state.tensors[\"site_3\"]\n",
    "tdvp.state.tensors[\"site_3\"] = ptn.time_evolve(psi,hamiltonian_eff_site,\n",
    "                                                   tdvp.time_step_size,\n",
    "                                                   forward=True)\n",
    "\n",
    "u = expm(-1j*0.1*hamiltonian_eff_site2)\n",
    "u = u.reshape(6,5,6,5)\n",
    "ref_mps.tensors[\"site_3\"] = np.tensordot(u, ref_mps.tensors[\"site_3\"],\n",
    "                                                 axes=((2,3),(0,1)))\n",
    "\n",
    "print(np.allclose(tdvp.state.tensors[\"site_3\"] , ref_mps.tensors[\"site_3\"]))\n",
    "\n",
    "# tdvp.update_link(\"site_3\",\"site_2\") :\n",
    "tdvp._split_updated_site(\"site_3\",\"site_2\")\n",
    "\n",
    "q, r = ptn.tensor_qr_decomposition(ref_mps.tensors[\"site_3\"],\n",
    "                                    (len(ref_mps.nodes[\"site_3\"].shape)-1, ), # 1\n",
    "                                    (ref_mps.nodes[\"site_3\"].neighbour_index(\"site_2\"), ), # 0\n",
    "                                    mode= ptn.SplitMode.KEEP)\n",
    "ref_mps.tensors[\"site_3\"] = q.transpose(1,0)\n",
    "new_cache = contract_leaf(\"site_3\", ref_mps, mpo)\n",
    "ref_cache_dict.add_entry(\"site_3\", \"site_2\", new_cache)\n",
    "\n",
    "print(np.allclose(tdvp.state.tensors[\"site_3\"] , ref_mps.tensors[\"site_3\"]))\n",
    "print(np.allclose(new_cache, tdvp.partial_tree_cache.get_entry(\"site_3\", \"site_2\")))\n",
    "\n",
    "tdvp._time_evolve_link_tensor(\"site_3\",\"site_2\")\n",
    "\n",
    "heff = np.tensordot(ref_cache_dict.get_entry(\"site_2\", \"site_3\"),\n",
    "                    ref_cache_dict.get_entry(\"site_3\", \"site_2\"),\n",
    "                    axes=(1,1))\n",
    "heff = np.transpose(heff, (1,3,0,2)).reshape(36,36)\n",
    "\n",
    "u = expm(1j*0.1*heff)\n",
    "u = u.reshape(6,6,6,6)\n",
    "updated_r = np.tensordot(u,r,axes=((2,3),(1,0)))\n",
    "\n",
    "np.allclose(heff, tdvp._get_effective_link_hamiltonian(\"site_3\", \"site_2\"))\n",
    "\n",
    "tdvp.state.contract_nodes('link_site_3_with_site_2', \"site_2\", new_identifier=\"site_2\")\n",
    "\n",
    "next_site = np.tensordot(ref_mps.tensors[\"site_2\"],\n",
    "                                 updated_r,\n",
    "                                 axes=(1,0))\n",
    "next_site = next_site.transpose(0,2,1)\n",
    "ref_mps.tensors[\"site_2\"] = next_site\n",
    "ref_mps.orthogonality_center_id = \"site_2\"\n",
    "\n",
    "print(np.allclose(tdvp.state.tensors[\"site_2\"], ref_mps.tensors[\"site_2\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
